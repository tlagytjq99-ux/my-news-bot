import feedparser
import csv
import urllib.parse
from datetime import datetime, timedelta
from googlenewsdecoder import gnewsdecoder
import time

def main():
    # 1. ì„¤ì •: ìµœê·¼ 1ì£¼ì¼(7ì¼) ë° ì¤‘êµ­ì–´ í‚¤ì›Œë“œ
    days_limit = 7
    # "äººå·¥æ™ºèƒ½ æ”¿ç­–" (ì¸ê³µì§€ëŠ¥ ì •ì±…) í‚¤ì›Œë“œ ì‚¬ìš©
    keyword = '"äººå·¥æ™ºèƒ½ æ”¿ç­–"' 
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days_limit)
    
    # 2. ì¤‘êµ­ êµ¬ê¸€ ë‰´ìŠ¤ RSS ì¿¼ë¦¬ ìƒì„±
    # hl=zh-CN (ì¤‘êµ­ì–´ ê°„ì²´), gl=CN (ì¤‘êµ­ ì§€ì—­) ì„¤ì •
    encoded_query = urllib.parse.quote(keyword)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-CN&gl=CN&ceid=CN:zh-Hans"

    print(f"ğŸ“¡ ì¤‘êµ­ êµ¬ê¸€ ë‰´ìŠ¤ì—ì„œ '{keyword}' ê´€ë ¨ ì†Œì‹ ìˆ˜ì§‘ ì¤‘... (ìµœê·¼ {days_limit}ì¼)")

    try:
        feed = feedparser.parse(rss_url)
        all_data = []

        for entry in feed.entries:
            try:
                pub_date_struct = entry.published_parsed
                pub_date_obj = datetime(*pub_date_struct[:3])
            except:
                continue

            # 1ì£¼ì¼ ì´ë‚´ ë°ì´í„° í•„í„°ë§
            if pub_date_obj >= start_date:
                raw_title = entry.title.split(' - ')[0].strip()
                
                # ë§í¬ í•´ë… (ì¤‘êµ­ ì–¸ë¡ ì‚¬ ì›ë¬¸ ì£¼ì†Œë¡œ ë³€í™˜)
                try:
                    decoded = gnewsdecoder(entry.link)
                    actual_link = decoded.get('decoded_url', entry.link)
                except:
                    actual_link = entry.link

                all_data.append({
                    "ë°œí–‰ì¼": pub_date_obj.strftime('%Y-%m-%d'),
                    "ì–¸ë¡ ì‚¬": entry.source.get('title', 'N/A') if hasattr(entry, 'source') else 'N/A',
                    "ì œëª©": raw_title,
                    "ì›ë¬¸ë§í¬": actual_link
                })
                time.sleep(0.1)

        # 3. CSV ì €ì¥
        file_name = 'china_ai_policy_report.csv'
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ë°œí–‰ì¼", "ì–¸ë¡ ì‚¬", "ì œëª©", "ì›ë¬¸ë§í¬"])
            writer.writeheader()
            if all_data:
                all_data.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)
                writer.writerows(all_data)
                print(f"âœ… ìˆ˜ì§‘ ì„±ê³µ: ì´ {len(all_data)}ê±´ì˜ ì¤‘êµ­ AI ì •ì±… ê´€ë ¨ ì†Œì‹ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"âš ï¸ ê²°ê³¼ ì—†ìŒ: ìµœê·¼ {days_limit}ì¼ ë‚´ì— í•´ë‹¹ í‚¤ì›Œë“œì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
