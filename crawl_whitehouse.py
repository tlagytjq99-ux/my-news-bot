import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime
from googletrans import Translator
import time

def crawl_whitehouse_ai():
    print("1. ë°±ì•…ê´€ ë‰´ìŠ¤ë£¸ ê³µëµ ì‹œì‘...")
    # ì•Œë ¤ì£¼ì‹  news í˜ì´ì§€ì˜ ë°ì´í„°ë¥¼ ë‹´ê³  ìˆëŠ” ê³µì‹ RSS í”¼ë“œì…ë‹ˆë‹¤.
    url = "https://www.whitehouse.gov/feed/"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    }
    
    translator = Translator()
    collect_date = datetime.now().strftime("%Y-%m-%d")
    
    try:
        # 1. í˜ì´ì§€ ì ‘ì†
        response = requests.get(url, headers=headers, timeout=20)
        response.raise_for_status() 
        
        # 2. ë°ì´í„° íŒŒì‹±
        root = ET.fromstring(response.content)
        print("2. ë°±ì•…ê´€ ë°ì´í„° ìˆ˜ì‹  ì„±ê³µ!")
        
    except Exception as e:
        print(f"âŒ ì ‘ì† ì‹¤íŒ¨: {e}")
        # ì—ëŸ¬ ì‹œ ë¹ˆ íŒŒì¼ ìƒì„± (ì›Œí¬í”Œë¡œìš° ì¤‘ë‹¨ ë°©ì§€)
        pd.DataFrame(columns=["ìˆ˜ì§‘ì¼", "ë°œí–‰ì¼", "ê¸°ê´€", "ì›ë¬¸ ì œëª©", "í•œê¸€ ë²ˆì—­ ì œëª©", "ë§í¬"]).to_excel("whitehouse_news.xlsx", index=False)
        return

    news_items = []
    # RSS í”¼ë“œ ë‚´ì˜ ê° ë‰´ìŠ¤ í•­ëª©(item) ì¶”ì¶œ
    items = root.findall(".//item")
    
    # AI ë° í•µì‹¬ ê¸°ìˆ  í‚¤ì›Œë“œ
    ai_keywords = ["AI", "Artificial Intelligence", "Technology", "Cyber", "Quantum", "Semiconductor", "Digital", "Security"]
    
    print(f"3. ì´ {len(items)}ê°œ ë‰´ìŠ¤ ì¤‘ AI ê´€ë ¨ ë‰´ìŠ¤ í•„í„°ë§ ì‹œì‘...")

    for item in items:
        title_en = item.find("title").text
        link = item.find("link").text
        pub_date_raw = item.find("pubDate").text # ì˜ˆ: Tue, 27 Jan 2026...

        # ì œëª©ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê²€ì‚¬
        if any(kw.lower() in title_en.lower() for kw in ai_keywords):
            # ë‚ ì§œ ë³€í™˜ (yyyy-mm-dd)
            try:
                date_obj = datetime.strptime(pub_date_raw[5:16], "%d %b %Y")
                pub_date = date_obj.strftime("%Y-%m-%d")
            except:
                pub_date = pub_date_raw[:16]

            # ë²ˆì—­ ì²˜ë¦¬
            try:
                print(f"   [ë°œê²¬] {title_en[:50]}...")
                title_ko = translator.translate(title_en, src='en', dest='ko').text
                time.sleep(1.5) # ë²ˆì—­ê¸° ì°¨ë‹¨ ë°©ì§€ìš©
            except:
                title_ko = title_en

            news_items.append({
                "ìˆ˜ì§‘ì¼": collect_date,
                "ë°œí–‰ì¼": pub_date,
                "ê¸°ê´€": "White House",
                "ì›ë¬¸ ì œëª©": title_en,
                "í•œê¸€ ë²ˆì—­ ì œëª©": title_ko,
                "ë§í¬": link
            })
            
            # ë„ˆë¬´ ë§ìœ¼ë©´ ì‹œê°„ì´ ê±¸ë¦¬ë‹ˆ ìµœì‹  10ê°œë§Œ
            if len(news_items) >= 10: break

    # ë°ì´í„° ì €ì¥
    if news_items:
        df = pd.DataFrame(news_items)
        print(f"âœ… ì´ {len(news_items)}ê±´ì˜ ë°±ì•…ê´€ AI ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
    else:
        print("ğŸ” ìµœê·¼ AI ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ì—‘ì…€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
        df = pd.DataFrame(columns=["ìˆ˜ì§‘ì¼", "ë°œí–‰ì¼", "ê¸°ê´€", "ì›ë¬¸ ì œëª©", "í•œê¸€ ë²ˆì—­ ì œëª©", "ë§í¬"])
    
    df.to_excel("whitehouse_news.xlsx", index=False)

if __name__ == "__main__":
    crawl_whitehouse_ai()
