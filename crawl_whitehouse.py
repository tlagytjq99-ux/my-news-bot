import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime
from googletrans import Translator
import time
import os

def crawl_whitehouse_ai():
    print("1. ë°±ì•…ê´€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
    url = "https://www.whitehouse.gov/briefing-room/statements-releases/feed/"
    headers = {"User-Agent": "Mozilla/5.0"}
    translator = Translator()
    
    collect_date = datetime.now().strftime("%Y-%m-%d")
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        root = ET.fromstring(response.content)
    except Exception as e:
        print(f"ì ‘ì† ì—ëŸ¬: {e}")
        return

    news_items = []
    items = root.findall(".//item")
    ai_keywords = ["AI", "Artificial Intelligence", "Technology", "Quantum", "Cyber", "Semiconductor", "Chip", "Security"]
    
    for item in items[:50]:
        title_en = item.find("title").text
        link = item.find("link").text
        pub_date_raw = item.find("pubDate").text

        if any(kw.lower() in title_en.lower() for kw in ai_keywords):
            try:
                date_obj = datetime.strptime(pub_date_raw[5:16], "%d %b %Y")
                pub_date = date_obj.strftime("%Y-%m-%d")
            except:
                pub_date = pub_date_raw

            try:
                title_ko = translator.translate(title_en, src='en', dest='ko').text
                time.sleep(1)
            except:
                title_ko = title_en

            news_items.append({
                "ìˆ˜ì§‘ì¼": collect_date,
                "ë°œí–‰ì¼": pub_date,
                "ê¸°ê´€": "White House",
                "ì›ë¬¸ ì œëª©": title_en,
                "í•œê¸€ ë²ˆì—­ ì œëª©": title_ko,
                "ë§í¬": link
            })
            if len(news_items) >= 10: break

    # [ìˆ˜ì •] ë°ì´í„°ê°€ ì—†ë”ë¼ë„ ë¹ˆ íŒŒì¼ì´ë¼ë„ ìƒì„±í•˜ì—¬ ê¹ƒí—ˆë¸Œ ì—ëŸ¬ ë°©ì§€
    if not news_items:
        print("ğŸ” ìµœê·¼ AI ê´€ë ¨ ë°±ì•…ê´€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
        df = pd.DataFrame(columns=["ìˆ˜ì§‘ì¼", "ë°œí–‰ì¼", "ê¸°ê´€", "ì›ë¬¸ ì œëª©", "í•œê¸€ ë²ˆì—­ ì œëª©", "ë§í¬"])
    else:
        df = pd.DataFrame(news_items)
        print(f"âœ… ë°±ì•…ê´€ AI ë‰´ìŠ¤ {len(news_items)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ!")

    df.to_excel("whitehouse_news.xlsx", index=False)

if __name__ == "__main__":
    crawl_whitehouse_ai()
