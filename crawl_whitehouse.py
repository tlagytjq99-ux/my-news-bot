import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime
from googletrans import Translator
import time

def crawl_whitehouse_ai():
    print("1. ë°±ì•…ê´€ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œìž‘...")
    # ë°±ì•…ê´€ ë¸Œë¦¬í•‘ë£¸ RSS í”¼ë“œ
    url = "https://www.whitehouse.gov/briefing-room/statements-releases/feed/"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}
    translator = Translator()
    
    collect_date = datetime.now().strftime("%Y-%m-%d")
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        root = ET.fromstring(response.content)
        print("2. RSS ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
    except Exception as e:
        print(f"ì ‘ì† ì—ëŸ¬: {e}")
        return

    news_items = []
    items = root.findall(".//item")
    
    # AI ê´€ë ¨ í•µì‹¬ í‚¤ì›Œë“œ
    ai_keywords = ["AI", "Artificial Intelligence", "Technology", "Quantum", "Cyber", "Semiconductor", "Chip"]
    count = 0

    for item in items:
        title_en = item.find("title").text
        link = item.find("link").text
        pub_date_raw = item.find("pubDate").text

        # AI ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°ë§Œ ìˆ˜ì§‘
        if any(kw.lower() in title_en.lower() for kw in ai_keywords):
            # ë‚ ì§œ ë³€í™˜ (yyyy-mm-dd)
            try:
                date_obj = datetime.strptime(pub_date_raw[5:16], "%d %b %Y")
                pub_date = date_obj.strftime("%Y-%m-%d")
            except:
                pub_date = pub_date_raw

            # í•œê¸€ ë²ˆì—­
            try:
                print(f"   - ë²ˆì—­ ì¤‘: {title_en[:30]}...")
                title_ko = translator.translate(title_en, src='en', dest='ko').text
                time.sleep(1) # ì°¨ë‹¨ ë°©ì§€
            except:
                title_ko = title_en

            news_items.append({
                "ìˆ˜ì§‘ì¼": collect_date,
                "ë°œí–‰ì¼": pub_date,
                "ê¸°ê´€": "White House",
                "ì›ë¬¸ ì œëª©": title_en,
                "í•œê¸€ ë²ˆì—­ ì œëª©": title_ko,
                "ë§í¬": link
            })
            count += 1
            if count >= 10: break # ìµœì‹  AI ë‰´ìŠ¤ 10ê°œê¹Œì§€ë§Œ

    if news_items:
        df = pd.DataFrame(news_items)
        df.to_excel("whitehouse_news.xlsx", index=False)
        print(f"âœ… ë°±ì•…ê´€ AI ë‰´ìŠ¤ {len(news_items)}ê±´ ì €ìž¥ ì™„ë£Œ!")
    else:
        print("ðŸ”Ž ìµœê·¼ AI ê´€ë ¨ ë°±ì•…ê´€ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    crawl_whitehouse_ai()
