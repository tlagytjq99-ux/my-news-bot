import feedparser
import csv
import urllib.parse
import time
from datetime import datetime
from googletrans import Translator
from googlenewsdecoder import gnewsdecoder

def main():
    # ğŸ¯ ë„ë©”ì¸ ì£¼ì†Œì—ì„œ https:// ë° í•˜ìœ„ ê²½ë¡œë¥¼ ì œê±°í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.
    gov_agencies = [
        {"êµ­ê°€": "ë¯¸êµ­", "ê¸°ê´€": "ë°±ì•…ê´€", "ë„ë©”ì¸": "whitehouse.gov"},
        {"êµ­ê°€": "ë¯¸êµ­", "ê¸°ê´€": "DOC (ìƒë¬´ë¶€)", "ë„ë©”ì¸": "commerce.gov"},
        {"êµ­ê°€": "ë¯¸êµ­", "ê¸°ê´€": "NTIA", "ë„ë©”ì¸": "ntia.gov"},
        {"êµ­ê°€": "ì¤‘êµ­", "ê¸°ê´€": "CAC (ì‚¬ì´ë²„ê³µê°„ê´€ë¦¬êµ­)", "ë„ë©”ì¸": "cac.gov.cn"},
        {"êµ­ê°€": "ì¤‘êµ­", "ê¸°ê´€": "MIIT (ê³µì—…ì •ë³´í™”ë¶€)", "ë„ë©”ì¸": "miit.gov.cn"},
        {"êµ­ê°€": "ëŒ€í•œë¯¼êµ­", "ê¸°ê´€": "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€", "ë„ë©”ì¸": "msit.go.kr"},
        {"êµ­ê°€": "ëŒ€í•œë¯¼êµ­", "ê¸°ê´€": "ì‚°ì—…í†µìƒìì›ë¶€", "ë„ë©”ì¸": "motie.go.kr"},
        {"êµ­ê°€": "ì‹±ê°€í¬ë¥´", "ê¸°ê´€": "MDDI", "ë„ë©”ì¸": "mddi.gov.sg"},
        {"êµ­ê°€": "ì‹±ê°€í¬ë¥´", "ê¸°ê´€": "IMDA", "ë„ë©”ì¸": "imda.gov.sg"},
        {"êµ­ê°€": "ë…ì¼", "ê¸°ê´€": "BMDV", "ë„ë©”ì¸": "bmdv.bund.de"},
        {"êµ­ê°€": "ë…ì¼", "ê¸°ê´€": "BMWK", "ë„ë©”ì¸": "bmwk.de"},
        {"êµ­ê°€": "ì¼ë³¸", "ê¸°ê´€": "MIC (ì´ë¬´ì„±)", "ë„ë©”ì¸": "soumu.go.jp"},
        {"êµ­ê°€": "ì¼ë³¸", "ê¸°ê´€": "ë””ì§€í„¸ì²­", "ë„ë©”ì¸": "digital.go.jp"},
        {"êµ­ê°€": "ì¼ë³¸", "ê¸°ê´€": "METI (ê²½ì œì‚°ì—…ì„±)", "ë„ë©”ì¸": "meti.go.jp"},
        {"êµ­ê°€": "ì˜êµ­", "ê¸°ê´€": "DSIT", "ë„ë©”ì¸": "www.gov.uk/government/organisations/department-for-science-innovation-and-technology"},
        {"êµ­ê°€": "ì˜êµ­", "ê¸°ê´€": "DBT", "ë„ë©”ì¸": "www.gov.uk/government/organisations/department-for-business-and-trade"},
        {"êµ­ê°€": "ë„¤ëœë€ë“œ", "ê¸°ê´€": "EZK", "ë„ë©”ì¸": "government.nl"},
        {"êµ­ê°€": "ìŠ¤ì›¨ë´", "ê¸°ê´€": "Ministry of Finance", "ë„ë©”ì¸": "government.se"},
        {"êµ­ê°€": "í•€ë€ë“œ", "ê¸°ê´€": "LVM", "ë„ë©”ì¸": "lvm.fi"},
        {"êµ­ê°€": "í•€ë€ë“œ", "ê¸°ê´€": "MEE", "ë„ë©”ì¸": "tem.fi"},
        {"êµ­ê°€": "ìŠ¤ìœ„ìŠ¤", "ê¸°ê´€": "OFCOM", "ë„ë©”ì¸": "bakom.admin.ch"},
        {"êµ­ê°€": "ë´ë§ˆí¬", "ê¸°ê´€": "Digitaliseringsstyrelsen", "ë„ë©”ì¸": "digst.dk"},
        {"êµ­ê°€": "ë…¸ë¥´ì›¨ì´", "ê¸°ê´€": "KDD", "ë„ë©”ì¸": "regjeringen.no"},
        {"êµ­ê°€": "ì´ìŠ¤ë¼ì—˜", "ê¸°ê´€": "IIA", "ë„ë©”ì¸": "innovationisrael.org.il"},
        {"êµ­ê°€": "ìºë‚˜ë‹¤", "ê¸°ê´€": "ISED", "ë„ë©”ì¸": "ised-isde.canada.ca"},
        {"êµ­ê°€": "í”„ë‘ìŠ¤", "ê¸°ê´€": "Bercy", "ë„ë©”ì¸": "economie.gouv.fr"},
        {"êµ­ê°€": "í˜¸ì£¼", "ê¸°ê´€": "DISR", "ë„ë©”ì¸": "industry.gov.au"},
        {"êµ­ê°€": "ëŒ€ë§Œ", "ê¸°ê´€": "moda", "ë„ë©”ì¸": "moda.gov.tw"},
        {"êµ­ê°€": "UAE", "ê¸°ê´€": "TDRA", "ë„ë©”ì¸": "tdra.gov.ae"},
        {"êµ­ê°€": "ì‚¬ìš°ë””", "ê¸°ê´€": "MCIT", "ë„ë©”ì¸": "mcit.gov.sa"}
    ]

    all_final_data = []
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")
    file_name = f'global_ict_policy_intelligence_{collected_date}.csv'

    print(f"ğŸ“¡ ê°œì„ ëœ ì¿¼ë¦¬ë¡œ {len(gov_agencies)}ê°œ ê¸°ê´€ ì¬ìˆ˜ì§‘ ì‹œì‘...")

    for agency in gov_agencies:
        print(f"ğŸ” [{agency['êµ­ê°€']}] {agency['ê¸°ê´€']} íƒìƒ‰ ì¤‘...")
        
        # ğŸ’¡ [ê°œì„ ] intitle ì œì•½ì„ ì œê±°í•˜ê³  ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ í™•ì¥í–ˆìŠµë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ ì œëª©ì— AIê°€ ì—†ì–´ë„ ë³¸ë¬¸ ë‚´ìš©ì— ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìˆ˜ì§‘ë©ë‹ˆë‹¤.
        query = f'site:{agency["ë„ë©”ì¸"]} ("Artificial Intelligence" OR AI OR ICT OR "Digital Policy")'
        encoded_query = urllib.parse.quote(query)
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"

        try:
            feed = feedparser.parse(rss_url)
            count = 0

            for entry in feed.entries:
                if count >= 3: break 
                
                title_en = entry.title.split(' - ')[0]
                
                # ë§í¬ í•´ë…
                try:
                    decoded = gnewsdecoder(entry.link)
                    actual_link = decoded.get('decoded_url', entry.link)
                except:
                    actual_link = entry.link

                # ë°œí–‰ì¼ ì²˜ë¦¬
                pub_date = "N/A"
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_date = datetime(*entry.published_parsed[:3]).strftime('%Y-%m-%d')

                # ë²ˆì—­ ì²˜ë¦¬
                try:
                    title_ko = title_en if agency['êµ­ê°€'] == "ëŒ€í•œë¯¼êµ­" else translator.translate(title_en.strip(), dest='ko').text
                except:
                    title_ko = title_en
                
                all_final_data.append({
                    "êµ­ê°€": agency["êµ­ê°€"],
                    "ê¸°ê´€": agency["ê¸°ê´€"],
                    "ë°œí–‰ì¼": pub_date,
                    "ì œëª©": title_ko,
                    "ì›ë¬¸": title_en,
                    "ë§í¬": actual_link,
                    "ìˆ˜ì§‘ì¼": collected_date
                })
                count += 1

            time.sleep(1.5) # ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ ì‹œê°„ì„ ì•½ê°„ ë” ëŠ˜ë ¸ìŠµë‹ˆë‹¤.

        except Exception as e:
            print(f"âŒ {agency['ê¸°ê´€']} ì˜¤ë¥˜: {e}")

    # ğŸ’¾ ê²°ê³¼ ì €ì¥
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["êµ­ê°€", "ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬", "ìˆ˜ì§‘ì¼"])
        writer.writeheader()
        writer.writerows(all_final_data)
        
    print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ! {len(all_final_data)}ê±´ ì €ì¥ ì™„ë£Œ.")

if __name__ == "__main__":
    main()
