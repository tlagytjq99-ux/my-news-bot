import feedparser
import csv
import urllib.parse
import time
from datetime import datetime
from googletrans import Translator
from googlenewsdecoder import gnewsdecoder

def get_localized_query(agency):
    """êµ­ê°€ë³„ íŠ¹ì„±ì— ë§ì¶˜ ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
    country = agency['êµ­ê°€']
    domain = agency['ë„ë©”ì¸']
    kw = '("Artificial Intelligence" OR AI OR "Digital Policy" OR ICT)'
    
    if country == "ëŒ€í•œë¯¼êµ­":
        kw = '("ì¸ê³µì§€ëŠ¥" OR AI OR "ë””ì§€í„¸" OR "ë°ì´í„°")'
    elif country == "ì¼ë³¸":
        kw = '("äººå·¥çŸ¥èƒ½" OR AI OR "ãƒ‡ã‚¸ã‚¿ãƒ«æ”¿ç­–" OR "ICT")'
    elif country in ["ì¤‘êµ­", "ëŒ€ë§Œ"]:
        kw = '("äººå·¥æ™ºèƒ½" OR AI OR "æ•°å­—åŒ–" OR "é€šä¿¡")'
    elif country in ["ë…ì¼", "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„"]:
        kw = '("KÃ¼nstliche Intelligenz" OR KI OR "Digitalisierung")'
    elif country == "í”„ë‘ìŠ¤":
        kw = '("Intelligence Artificielle" OR IA OR "NumÃ©rique")'
    elif country in ["ë…¸ë¥´ì›¨ì´", "ìŠ¤ì›¨ë´", "ë´ë§ˆí¬", "í•€ë€ë“œ"]:
        kw = '("Artificial Intelligence" OR AI OR "Digitalisering")'
        
    return f'site:{domain} {kw}'

def main():
    # ğŸ¯ ëŒ€í‘œë‹˜ì´ ì œê³µí•˜ì‹  50ì—¬ ê°œ ì •ë¶€ê¸°ê´€ ì „ì²´ ë¦¬ìŠ¤íŠ¸
    gov_agencies = [
        {"êµ­ê°€": "ë¯¸êµ­", "ê¸°ê´€": "ë°±ì•…ê´€", "ë„ë©”ì¸": "whitehouse.gov"},
        {"êµ­ê°€": "ë¯¸êµ­", "ê¸°ê´€": "DOC", "ë„ë©”ì¸": "commerce.gov"},
        {"êµ­ê°€": "ë¯¸êµ­", "ê¸°ê´€": "NTIA", "ë„ë©”ì¸": "ntia.gov"},
        {"êµ­ê°€": "ì¤‘êµ­", "ê¸°ê´€": "CAC", "ë„ë©”ì¸": "cac.gov.cn"},
        {"êµ­ê°€": "ì¤‘êµ­", "ê¸°ê´€": "MIIT", "ë„ë©”ì¸": "miit.gov.cn"},
        {"êµ­ê°€": "ëŒ€í•œë¯¼êµ­", "ê¸°ê´€": "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€", "ë„ë©”ì¸": "msit.go.kr"},
        {"êµ­ê°€": "ëŒ€í•œë¯¼êµ­", "ê¸°ê´€": "ì‚°ì—…í†µìƒìì›ë¶€", "ë„ë©”ì¸": "motie.go.kr"},
        {"êµ­ê°€": "ì‹±ê°€í¬ë¥´", "ê¸°ê´€": "MDDI", "ë„ë©”ì¸": "mddi.gov.sg"},
        {"êµ­ê°€": "ì‹±ê°€í¬ë¥´", "ê¸°ê´€": "IMDA", "ë„ë©”ì¸": "imda.gov.sg"},
        {"êµ­ê°€": "ë…ì¼", "ê¸°ê´€": "BMDV", "ë„ë©”ì¸": "bmdv.bund.de"},
        {"êµ­ê°€": "ë…ì¼", "ê¸°ê´€": "BMWK", "ë„ë©”ì¸": "bmwk.de"},
        {"êµ­ê°€": "ì¼ë³¸", "ê¸°ê´€": "MIC", "ë„ë©”ì¸": "soumu.go.jp"},
        {"êµ­ê°€": "ì¼ë³¸", "ê¸°ê´€": "ë””ì§€í„¸ì²­", "ë„ë©”ì¸": "digital.go.jp"},
        {"êµ­ê°€": "ì¼ë³¸", "ê¸°ê´€": "METI", "ë„ë©”ì¸": "meti.go.jp"},
        {"êµ­ê°€": "ì˜êµ­", "ê¸°ê´€": "DSIT", "ë„ë©”ì¸": "gov.uk/government/organisations/department-for-science-innovation-and-technology"},
        {"êµ­ê°€": "ì˜êµ­", "ê¸°ê´€": "DBT", "ë„ë©”ì¸": "gov.uk/government/organisations/department-for-business-and-trade"},
        {"êµ­ê°€": "ë„¤ëœë€ë“œ", "ê¸°ê´€": "EZK", "ë„ë©”ì¸": "government.nl"},
        {"êµ­ê°€": "ë„¤ëœë€ë“œ", "ê¸°ê´€": "Digitalisation", "ë„ë©”ì¸": "nldigitalgovernment.nl"},
        {"êµ­ê°€": "ìŠ¤ì›¨ë´", "ê¸°ê´€": "Finance", "ë„ë©”ì¸": "government.se/government-of-sweden/ministry-of-finance"},
        {"êµ­ê°€": "ìŠ¤ì›¨ë´", "ê¸°ê´€": "Climate", "ë„ë©”ì¸": "government.se/government-of-sweden/ministry-of-climate-and-enterprise"},
        {"êµ­ê°€": "í•€ë€ë“œ", "ê¸°ê´€": "LVM", "ë„ë©”ì¸": "lvm.fi"},
        {"êµ­ê°€": "í•€ë€ë“œ", "ê¸°ê´€": "MEE", "ë„ë©”ì¸": "tem.fi"},
        {"êµ­ê°€": "ìŠ¤ìœ„ìŠ¤", "ê¸°ê´€": "OFCOM", "ë„ë©”ì¸": "bakom.admin.ch"},
        {"êµ­ê°€": "ìŠ¤ìœ„ìŠ¤", "ê¸°ê´€": "WBF", "ë„ë©”ì¸": "wbf.admin.ch"},
        {"êµ­ê°€": "ë´ë§ˆí¬", "ê¸°ê´€": "Digitaliseringsstyrelsen", "ë„ë©”ì¸": "digst.dk"},
        {"êµ­ê°€": "ë´ë§ˆí¬", "ê¸°ê´€": "Erhvervsministeriet", "ë„ë©”ì¸": "em.dk"},
        {"êµ­ê°€": "ë…¸ë¥´ì›¨ì´", "ê¸°ê´€": "KDD", "ë„ë©”ì¸": "regjeringen.no/en/dep/kdd"},
        {"êµ­ê°€": "ë…¸ë¥´ì›¨ì´", "ê¸°ê´€": "NFD", "ë„ë©”ì¸": "regjeringen.no/en/dep/nfd"},
        {"êµ­ê°€": "ì´ìŠ¤ë¼ì—˜", "ê¸°ê´€": "IIA", "ë„ë©”ì¸": "innovationisrael.org.il"},
        {"êµ­ê°€": "ì´ìŠ¤ë¼ì—˜", "ê¸°ê´€": "MoC", "ë„ë©”ì¸": "gov.il/en/departments/ministry_of_communications"},
        {"êµ­ê°€": "ì´ìŠ¤ë¼ì—˜", "ê¸°ê´€": "Economy", "ë„ë©”ì¸": "gov.il/en/departments/ministry_of_economy"},
        {"êµ­ê°€": "ìºë‚˜ë‹¤", "ê¸°ê´€": "ISED", "ë„ë©”ì¸": "ised-isde.canada.ca"},
        {"êµ­ê°€": "ìºë‚˜ë‹¤", "ê¸°ê´€": "TBS", "ë„ë©”ì¸": "canada.ca/en/treasury-board-secretariat"},
        {"êµ­ê°€": "í”„ë‘ìŠ¤", "ê¸°ê´€": "Bercy", "ë„ë©”ì¸": "economie.gouv.fr"},
        {"êµ­ê°€": "í”„ë‘ìŠ¤", "ê¸°ê´€": "DG Entreprises", "ë„ë©”ì¸": "entreprises.gouv.fr"},
        {"êµ­ê°€": "í˜¸ì£¼", "ê¸°ê´€": "DITRDCA", "ë„ë©”ì¸": "infrastructure.gov.au"},
        {"êµ­ê°€": "í˜¸ì£¼", "ê¸°ê´€": "DISR", "ë„ë©”ì¸": "industry.gov.au"},
        {"êµ­ê°€": "ì•„ì¼ëœë“œ", "ê¸°ê´€": "DECC", "ë„ë©”ì¸": "gov.ie/en/organisation/department-of-the-environment-climate-and-communications"},
        {"êµ­ê°€": "ì•„ì¼ëœë“œ", "ê¸°ê´€": "DETE", "ë„ë©”ì¸": "enterprise.gov.ie"},
        {"êµ­ê°€": "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„", "ê¸°ê´€": "BMF", "ë„ë©”ì¸": "bmf.gv.at"},
        {"êµ­ê°€": "ì˜¤ìŠ¤íŠ¸ë¦¬ì•„", "ê¸°ê´€": "BMAW", "ë„ë©”ì¸": "bmwet.gv.at"},
        {"êµ­ê°€": "ë²¨ê¸°ì—", "ê¸°ê´€": "ì—°ë°©í˜ì‹ ê¸°ìˆ ë¶€", "ë„ë©”ì¸": "belspo.be"},
        {"êµ­ê°€": "ë²¨ê¸°ì—", "ê¸°ê´€": "BIPT", "ë„ë©”ì¸": "bipt.be"},
        {"êµ­ê°€": "ë²¨ê¸°ì—", "ê¸°ê´€": "FPS Economy", "ë„ë©”ì¸": "economie.fgov.be"},
        {"êµ­ê°€": "ëŒ€ë§Œ", "ê¸°ê´€": "moda", "ë„ë©”ì¸": "moda.gov.tw"},
        {"êµ­ê°€": "ëŒ€ë§Œ", "ê¸°ê´€": "MOEA", "ë„ë©”ì¸": "moea.gov.tw"},
        {"êµ­ê°€": "UAE", "ê¸°ê´€": "TDRA", "ë„ë©”ì¸": "tdra.gov.ae"},
        {"êµ­ê°€": "UAE", "ê¸°ê´€": "MoIAT", "ë„ë©”ì¸": "moiat.gov.ae"},
        {"êµ­ê°€": "ì‚¬ìš°ë””", "ê¸°ê´€": "MCIT", "ë„ë©”ì¸": "mcit.gov.sa"},
        {"êµ­ê°€": "ì‚¬ìš°ë””", "ê¸°ê´€": "MIM", "ë„ë©”ì¸": "mim.gov.sa"}
    ]

    all_final_data = []
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")
    file_name = f'global_ict_policy_final_{collected_date}.csv'
    
    # ğŸ›¡ï¸ ì œì™¸í•  ë…¸ì´ì¦ˆ ì œëª© í‚¤ì›Œë“œ
    noise_keywords = ["HOMEPAGE", "PRESS RELEASES", "NEWS", "ABOUT", "PLAIN LANGUAGE", "HAKU", "WHAT'S NEW", "CONTACT US"]

    print(f"ğŸ“¡ {collected_date} ê¸€ë¡œë²Œ 50ê°œ ê¸°ê´€ ìµœì‹  ë°ì´í„° ìˆ˜ì§‘ ë° ì •ì œ ì‹œì‘...")

    for agency in gov_agencies:
        print(f"ğŸ” [{agency['êµ­ê°€']}] {agency['ê¸°ê´€']} í•„í„°ë§ ìˆ˜ì§‘ ì¤‘...")
        
        query = get_localized_query(agency)
        encoded_query = urllib.parse.quote(query)
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"

        try:
            feed = feedparser.parse(rss_url)
            count = 0

            for entry in feed.entries:
                if count >= 3: break 
                
                title_en = entry.title.split(' - ')[0]
                
                # 1ï¸âƒ£ ë…¸ì´ì¦ˆ í•„í„°ë§: ì•Œë§¹ì´ ì—†ëŠ” ì œëª© ì œì™¸
                if any(noise in title_en.upper() for noise in noise_keywords):
                    continue
                if len(title_en.split()) < 3: # ë„ˆë¬´ ì§§ì€ ì œëª© ì œì™¸
                    continue

                # 2ï¸âƒ£ ë‚ ì§œ í•„í„°ë§: 2024ë…„ ì´í›„ ë°ì´í„°ë§Œ í—ˆìš©
                pub_date = "N/A"
                if hasattr(entry, 'published_parsed') and entry.published_parsed:
                    pub_year = entry.published_parsed[0]
                    if pub_year < 2024: 
                        continue
                    pub_date = datetime(*entry.published_parsed[:3]).strftime('%Y-%m-%d')

                # ë§í¬ í•´ë…
                try:
                    decoded = gnewsdecoder(entry.link)
                    actual_link = decoded.get('decoded_url', entry.link)
                except:
                    actual_link = entry.link

                # ë²ˆì—­ (í•œêµ­ ì œì™¸)
                try:
                    title_ko = title_en if agency['êµ­ê°€'] == "ëŒ€í•œë¯¼êµ­" else translator.translate(title_en.strip(), dest='ko').text
                except:
                    title_ko = title_en
                
                all_final_data.append({
                    "êµ­ê°€": agency["êµ­ê°€"],
                    "ê¸°ê´€": agency["ê¸°ê´€"],
                    "ë°œí–‰ì¼": pub_date,
                    "ì œëª©": title_ko,
                    "ì›ë¬¸": title_en,
                    "ë§í¬": actual_link,
                    "ìˆ˜ì§‘ì¼": collected_date
                })
                count += 1

            time.sleep(1.5) # êµ¬ê¸€ ì°¨ë‹¨ ë°©ì§€ ë§¤ë„ˆ íƒ€ì„

        except Exception as e:
            print(f"âŒ {agency['ê¸°ê´€']} ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

    # ğŸ’¾ ê²°ê³¼ ì €ì¥ (BOM í¬í•¨ UTF-8ë¡œ ì—‘ì…€ í˜¸í™˜ì„± í™•ë³´)
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["êµ­ê°€", "ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬", "ìˆ˜ì§‘ì¼"])
        writer.writeheader()
        writer.writerows(all_final_data)
        
    print(f"\nâœ… ìˆ˜ì§‘ ë° ì •ì œ ì™„ë£Œ! ì´ {len(all_final_data)}ê±´ ì €ì¥ë¨.")

if __name__ == "__main__":
    main()
