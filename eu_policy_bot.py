import requests
import csv
import os

def fetch_eu_cellar_sparql():
    # Cellar ê³µì‹ SPARQL ì—”ë“œí¬ì¸íŠ¸
    sparql_url = "https://publications.europa.eu/webapi/rdf/sparql"
    
    # 2025ë…„ ì˜ì–´ ì •ì±… ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” SPARQL ì¿¼ë¦¬
    query = """
    PREFIX cdm: <http://publications.europa.eu/ontology/cdm#>
    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

    SELECT DISTINCT ?work ?title ?date
    WHERE {
      ?work cdm:work_date_document ?date .
      ?work cdm:work_has_resource-type ?type .
      ?work cdm:work_has_expression ?expr .
      ?expr cdm:expression_title ?title .
      ?expr cdm:expression_uses_language <http://publications.europa.eu/resource/authority/language/ENG> .
      
      FILTER(?date >= "2025-01-01"^^xsd:date && ?date <= "2025-12-31"^^xsd:date)
    }
    ORDER BY DESC(?date)
    LIMIT 1000
    """

    file_name = 'EU_Policy_2025_Full.csv'
    headers = {
        "Accept": "application/sparql-results+json",
        "User-Agent": "Mozilla/5.0"
    }

    print("ğŸš€ [Cellar SPARQL íƒ€ê²©] 2025ë…„ ì •ì±… DBì— ì§ì ‘ ì¿¼ë¦¬ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤...", flush=True)

    try:
        response = requests.get(sparql_url, params={'query': query}, headers=headers, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            results = data.get('results', {}).get('bindings', [])
            
            all_records = []
            for item in results:
                # Cellar ê³ ìœ  ID ì¶”ì¶œ (URIì—ì„œ IDë§Œ ë¶„ë¦¬)
                work_uri = item['work']['value']
                cellar_id = work_uri.split('/')[-1]
                
                title = item['title']['value']
                date = item['date']['value']
                link = f"https://op.europa.eu/en/publication-detail/-/publication/{cellar_id}"
                
                all_records.append({
                    "date": date,
                    "title": title,
                    "link": link
                })
            
            # ì €ì¥ ë¡œì§
            if all_records:
                with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                    writer.writeheader()
                    writer.writerows(all_records)
                print(f"âœ… [ì„±ê³µ] ì´ {len(all_records)}ê±´ì˜ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ì—¬ {file_name}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤!", flush=True)
            else:
                print("âš ï¸ ì¿¼ë¦¬ëŠ” ì„±ê³µí–ˆìœ¼ë‚˜ ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤.", flush=True)
        else:
            print(f"âŒ SPARQL ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}", flush=True)
            print(f"ìƒì„¸ ë‚´ìš©: {response.text[:200]}", flush=True)

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

if __name__ == "__main__":
    fetch_eu_cellar_sparql()
