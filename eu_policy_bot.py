import requests
import csv
from datetime import datetime
from xml.etree import ElementTree
from bs4 import BeautifulSoup
import time
import os

def fetch_eu_today_policy():
    # 1. ì˜¤ëŠ˜ ë‚ ì§œ ì„¤ì • (2026-02-09)
    today = datetime.now().strftime('%Y-%m-%d')
    
    # 2. EU ì•Œë¦¼ ì„œë¹„ìŠ¤ API í˜¸ì¶œ (ì˜¤ëŠ˜ ìƒì„±ëœ ëª¨ë“  ë¬¸ì„œ ëŒ€ìƒ)
    url = "http://publications.europa.eu/webapi/notification/ingestion"
    params = {
        "startDate": today,
        "type": "CREATE",
        "pageSize": "100" 
    }
    headers = {"Accept": "application/rss+xml", "User-Agent": "Mozilla/5.0"}

    print(f"ğŸ•µï¸ [ì˜¤ëŠ˜ì˜ ì •ì±… íƒìƒ‰] {today}ì ë¬¸ì„œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...", flush=True)
    policy_data = []

    try:
        response = requests.get(url, params=params, headers=headers, timeout=60)
        root = ElementTree.fromstring(response.content)
        items = root.findall('.//item')

        for item in items:
            cellar_id = "N/A"
            for child in item:
                if 'cellarId' in child.tag:
                    cellar_id = child.text.replace('cellar:', '')
                    break
            
            if cellar_id != "N/A":
                # ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ìš”ì•½ í˜ì´ì§€
                display_link = f"https://publications.europa.eu/en/publication-detail/-/publication/{cellar_id}"
                
                try:
                    # ì„œë²„ ë¶€í•˜ ë°©ì§€ ë° ì •ë°€ íŒŒì‹±
                    time.sleep(0.5)
                    detail_res = requests.get(display_link + "?language=en", headers=headers, timeout=10)
                    soup = BeautifulSoup(detail_res.text, 'html.parser')
                    
                    # ì œëª© ì¶”ì¶œ (h1 íƒœê·¸ ë˜ëŠ” title íƒœê·¸)
                    title = ""
                    h1_title = soup.find('h1', class_='document-title')
                    if h1_title:
                        title = h1_title.get_text(strip=True)
                    elif soup.title:
                        title = soup.title.string.split(' - ')[0].replace('Publication detail', '').strip()

                    # 3. [ì¤‘ìš”] ì •ì±… í•„í„°ë§ ë¡œì§
                    # 'ë²•(Law)'ë³´ë‹¤ëŠ” 'ë°©í–¥ì„±(Policy)'ì„ ë‚˜íƒ€ë‚´ëŠ” ë‹¨ì–´ë“¤
                    policy_keywords = ["Report", "Communication", "Strategy", "Proposal", "Action Plan", "Working Document", "COM(", "SWD(", "Opinion", "Notice"]
                    # ë‹¨ìˆœ ì ˆì°¨ì„± ë²•ë ¹/ì˜¤íƒ€ ìˆ˜ì •ì€ ì œì™¸
                    exclude_keywords = ["Rettifica", "Berichtigung", "Rectificatif", "Decision of the Court"]

                    is_policy = any(pk.lower() in title.lower() for pk in policy_keywords)
                    is_excluded = any(ek.lower() in title.lower() for ek in exclude_keywords)

                    if is_policy and not is_excluded:
                        policy_data.append({
                            "date": today,
                            "title": title,
                            "link": display_link
                        })
                        print(f"ğŸ¯ ì •ì±… ë°œê²¬: {title[:60]}...", flush=True)
                except:
                    continue
                    
    except Exception as e:
        print(f"âŒ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}", flush=True)

    # 4. ê²°ê³¼ ì €ì¥ (Append ëª¨ë“œ)
    save_to_csv(policy_data)

def save_to_csv(new_data):
    file_name = 'EU_Today_Policy_Test.csv'
    file_exists = os.path.isfile(file_name)
    
    with open(file_name, 'a', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
        if not file_exists:
            writer.writeheader()
        if new_data:
            writer.writerows(new_data)
            print(f"ğŸ’¾ ì´ {len(new_data)}ê±´ì˜ ì˜¤ëŠ˜ì ì •ì±… ë¦¬ìŠ¤íŠ¸ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", flush=True)
        else:
            print("â„¹ï¸ ì˜¤ëŠ˜ ìƒˆë¡œ ë°œí–‰ëœ ì •ì±… ë¬¸ì„œê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    fetch_eu_today_policy()
