import requests
from bs4 import BeautifulSoup
import csv

def crawl_eu_2025_news():
    # ëŒ€í‘œë‹˜ì´ ì£¼ì‹  2025ë…„ í•„í„°ë§ URL
    target_url = "https://european-union.europa.eu/news-and-events/news-and-stories_en?f%5B0%5D=oe_news_publication_date%3Abt%7C2025-01-01T02%3A12%3A07%2B01%3A00%7C2025-12-31T02%3A12%3A07%2B01%3A00"
    file_name = 'EU_News_2025_List.csv'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    print("ğŸš€ [2025 ë‰´ìŠ¤ ì‚¬ëƒ¥] ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤...", flush=True)

    try:
        response = requests.get(target_url, headers=headers, timeout=30)
        soup = BeautifulSoup(response.text, 'html.parser')

        # ê¸°ì‚¬ ì•„ì´í…œë“¤ì„ ì°¾ìŠµë‹ˆë‹¤ (ë³´í†µ íŠ¹ì • í´ë˜ìŠ¤ë¥¼ ê°€ì§„ div ë‚´ì— ì¡´ì¬)
        articles = soup.select('div.views-row') # í˜ì´ì§€ êµ¬ì¡°ì— ë”°ë¥¸ ì„ íƒì

        news_list = []
        for article in articles:
            # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
            title_tag = article.select_one('h3 a') or article.select_one('h2 a')
            if not title_tag: continue
            
            title = title_tag.get_text(strip=True)
            link = title_tag['href']
            if not link.startswith('http'):
                link = "https://european-union.europa.eu" + link

            # ë‚ ì§œ ì¶”ì¶œ
            date_tag = article.select_one('span.oe-news-publication-date') or article.select_one('time')
            date = date_tag.get_text(strip=True) if date_tag else "2025"

            news_list.append({
                "date": date,
                "title": title,
                "link": link
            })

        if news_list:
            with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                writer.writeheader()
                writer.writerows(news_list)
            
            print(f"âœ… ì„±ê³µ! 2025ë…„ ì£¼ìš” ë‰´ìŠ¤ {len(news_list)}ê±´ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ“‚ íŒŒì¼ëª…: {file_name}")
            # ìƒ˜í”Œ ì¶œë ¥
            print(f"\nğŸ“Œ ìµœì‹  ë‰´ìŠ¤ ì˜ˆì‹œ: {news_list[0]['title']}")
        else:
            print("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ êµ¬ì¡°ë¥¼ ë‹¤ì‹œ ë¶„ì„í•´ì•¼ í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    crawl_eu_2025_news()
