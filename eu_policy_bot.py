import requests
import csv
from datetime import datetime
from xml.etree import ElementTree
from bs4 import BeautifulSoup
import time

def fetch_eu_clean_data():
    today = datetime.now().strftime('%Y-%m-%d')
    # 2025ë…„ ë°ì´í„°ë¥¼ ìœ„í•´ ë‚ ì§œ ë²”ìœ„ë¥¼ ì‚´ì§ ë„“íˆê±°ë‚˜ íŠ¹ì • ì‹œì  íƒ€ê²ŸíŒ…
    url = "http://publications.europa.eu/webapi/notification/ingestion"
    params = {"startDate": today, "type": "CREATE", "wemiClasses": "work", "pageSize": "20"}
    headers = {"Accept": "application/rss+xml", "User-Agent": "Mozilla/5.0"}

    print(f"ğŸ“¡ ë°ì´í„° ì •í™” ì‘ì—… ì‹œì‘ (ì‚¬ëŒì´ ë³¼ ìˆ˜ ìˆëŠ” ë§í¬ë¡œ ë³€í™˜)...", flush=True)
    collected_data = []

    try:
        response = requests.get(url, params=params, headers=headers, timeout=30)
        root = ElementTree.fromstring(response.content)
        items = root.findall('.//item')

        for item in items:
            cellar_id = "N/A"
            for child in item:
                if 'cellarId' in child.tag:
                    cellar_id = child.text.replace('cellar:', '')
                    break
            
            if cellar_id != "N/A":
                # [ìˆ˜ì • 1] ì‚¬ëŒì´ ë³´ê¸° í¸í•œ ìƒì„¸ í˜ì´ì§€ ì£¼ì†Œë¡œ ìƒì„±
                # ì´ ì£¼ì†ŒëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì—´ë©´ í•´ë‹¹ ë¬¸ì„œì˜ ìš”ì•½ í˜ì´ì§€ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.
                display_link = f"https://publications.europa.eu/en/publication-detail/-/publication/{cellar_id}"
                
                # [ìˆ˜ì • 2] ì œëª© ì—­ì¶”ì  (ìƒì„¸ í˜ì´ì§€ì—ì„œ ì¶”ì¶œ)
                try:
                    time.sleep(1)
                    detail_res = requests.get(display_link, headers=headers, timeout=10)
                    if detail_res.status_code == 200:
                        soup = BeautifulSoup(detail_res.text, 'html.parser')
                        
                        # ì›¹í˜ì´ì§€ êµ¬ì¡°ì— ë”°ë¼ ì œëª© ìœ„ì¹˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìš°ì„ ìˆœìœ„ ì„¤ì •
                        title = "No Title"
                        if soup.title:
                            title = soup.title.string.split(' - ')[0].replace('Publication detail', '').strip()
                        
                        # ë§Œì•½ ì œëª©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ì´ìƒí•˜ë©´ ë‹¤ë¥¸ íƒœê·¸ íƒìƒ‰
                        if len(title) < 5 and soup.find('h1'):
                            title = soup.find('h1').get_text(strip=True)

                        collected_data.append({
                            "date": today,
                            "title": title,
                            "link": display_link
                        })
                        print(f"âœ… ìˆ˜ì§‘ì™„ë£Œ: {title[:40]}...", flush=True)
                except:
                    continue

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

    # ì €ì¥
    file_name = 'EU_Policy_2025_Full.csv'
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
        writer.writeheader()
        if collected_data:
            writer.writerows(collected_data)
        else:
            writer.writerow({"date": today, "title": "Searching...", "link": "N/A"})

if __name__ == "__main__":
    fetch_eu_clean_data()
