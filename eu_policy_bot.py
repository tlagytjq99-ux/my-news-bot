import csv
from SPARQLWrapper import SPARQLWrapper, JSON

def fetch_eu_cellar_sparql_final():
    endpoint_url = "https://publications.europa.eu/webapi/rdf/sparql"
    sparql = SPARQLWrapper(endpoint_url)
    
    # ì¿¼ë¦¬ ìˆ˜ì •: íŠ¹ì • íƒ€ì…ì„ ì§€ì •í•˜ì§€ ì•Šê³  '2025ë…„ ì´í›„ì˜ ëª¨ë“  ì˜ì–´ ì œëª© ë¬¸ì„œ'ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    query = """
    PREFIX cdm: <http://publications.europa.eu/ontology/cdm#>
    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

    SELECT DISTINCT ?work ?date ?title
    WHERE {
      ?work a cdm:work ;
            cdm:work_date_document ?date ;
            cdm:work_has_title ?title_res .
      ?title_res cdm:title_has_content ?title .
      
      # 2025ë…„ 1ì›” 1ì¼ ì´í›„ ë°ì´í„°
      FILTER(?date >= "2025-01-01"^^xsd:date)
      # ì˜ì–´ ì œëª©ë§Œ
      FILTER(lang(?title) = "en")
    }
    ORDER BY DESC(?date)
    LIMIT 200
    """
    
    sparql.setQuery(query)
    sparql.setReturnFormat(JSON)
    sparql.setTimeout(180) # ì„œë²„ ë¶€í•˜ë¥¼ ê³ ë ¤í•´ ëŒ€ê¸° ì‹œê°„ì„ 3ë¶„ìœ¼ë¡œ ëŠ˜ë¦¼

    print(f"ğŸ›ï¸ Cellar SPARQL ì—”ì§„ ì¬ì ‘ì† ì¤‘... (í•„í„° ì™„í™” ë²„ì „)", flush=True)
    
    file_name = 'EU_Policy_2025_Full.csv'
    collected_data = []

    try:
        results = sparql.query().convert()
        
        for result in results["results"]["bindings"]:
            work_url = result["work"]["value"]
            date = result["date"]["value"]
            title = result["title"]["value"]
            
            uuid = work_url.split('/')[-1]
            link = f"https://publications.europa.eu/resource/cellar/{uuid}"

            collected_data.append({
                "date": date,
                "title": title,
                "link": link
            })
            
        print(f"âœ… ìˆ˜ì§‘ ì„±ê³µ! 2025ë…„ ë°ì´í„° {len(collected_data)}ê±´ í™•ë³´ ì™„ë£Œ.", flush=True)

    except Exception as e:
        print(f"âŒ SPARQL ì¿¼ë¦¬ ì‹¤íŒ¨: {e}", flush=True)

    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
        writer.writeheader()
        if collected_data:
            writer.writerows(collected_data)
        else:
            # ì—¬ì „íˆ 0ê±´ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ê°€ìƒ ë°ì´í„°
            writer.writerow({"date": "2025-01-01", "title": "No Data Found - Check indexing status", "link": "N/A"})

if __name__ == "__main__":
    fetch_eu_cellar_sparql_final()
