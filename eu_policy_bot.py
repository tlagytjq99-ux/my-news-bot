import requests
import csv
import os
import time

def fetch_eu_data_hub_fixed():
    # 1. API ì£¼ì†Œ
    api_url = "https://data.europa.eu/api/hub/search/search"
    
    # 2. [ìˆ˜ì •] 400 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì •ë°€ íŒŒë¼ë¯¸í„° ì„¸íŒ…
    params = {
        "filters": "catalogue,dataset,resource", # API í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ìˆ˜ì •
        "dataScope": "eu",
        "dateType": "issued",
        "minDate": "2025-01-01T00:00:00.000Z",
        "maxDate": "2025-12-31T23:59:59.000Z",
        "includes": "id,title.en,issued",
        "limit": 50,  # ì•ˆì •ì„±ì„ ìœ„í•´ 50ê°œì”© ëŠì–´ì„œ ìš”ì²­
        "page": 0,
        "sort": "issued-desc" # ìµœì‹ ìˆœ ì •ë ¬ ì¶”ê°€
    }

    file_name = 'EU_Policy_2025_Full.csv'
    all_records = []
    
    print(f"ğŸ“¡ [ì¬ê°€ë™] EU API ì •ë°€ ì ‘ì† ì‹œë„ ì¤‘... (ëŒ€ìƒ: 2025ë…„ ì „ì²´)", flush=True)

    try:
        while True:
            response = requests.get(api_url, params=params, timeout=30)
            
            # ì‘ë‹µ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            if response.status_code != 200:
                print(f"âŒ ì„œë²„ ì‘ë‹µ ì—ëŸ¬: {response.status_code}", flush=True)
                print(f"âŒ ì—ëŸ¬ ë‚´ìš©: {response.text[:200]}", flush=True)
                break
            
            data = response.json()
            # ë°ì´í„° êµ¬ì¡° ì‹¬ì¸µ íƒìƒ‰
            results = data.get('result', {}).get('results', [])
            
            if not results:
                print("ğŸ ìˆ˜ì§‘ ì™„ë£Œ: ë” ì´ìƒì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", flush=True)
                break
            
            for item in results:
                # ì œëª© ì¶”ì¶œ (ì˜ì–´ ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ ì œëª©)
                title_dict = item.get('title', {})
                title = title_dict.get('en') if isinstance(title_dict, dict) else str(title_dict)
                if not title or title == 'None': title = "No English Title"
                
                issued_date = item.get('issued', '2025-XX-XX')
                doc_id = item.get('id', '')
                link = f"https://data.europa.eu/data/datasets/{doc_id}?locale=en"
                
                all_records.append({
                    "date": issued_date[:10],
                    "title": title.strip(),
                    "link": link
                })
            
            print(f"âœ… {params['page'] + 1}í˜ì´ì§€ ì™„ë£Œ (ëˆ„ì  {len(all_records)}ê±´ í™•ë³´)", flush=True)
            
            # ì „ìˆ˜ ì¡°ì‚¬ë¥¼ ìœ„í•´ í˜ì´ì§€ë¥¼ ê³„ì† ë„˜ê¹ë‹ˆë‹¤ (í…ŒìŠ¤íŠ¸ ì‹œ 5í˜ì´ì§€ë¡œ ì œí•œ ê°€ëŠ¥)
            params['page'] += 1
            if params['page'] > 100: break # ì•ˆì „ì¥ì¹˜: ìµœëŒ€ 5000ê±´ê¹Œì§€ë§Œ
            
            time.sleep(0.3) # ì„œë²„ ë¶€í•˜ ë°©ì§€

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

    # 3. íŒŒì¼ ì €ì¥ ë³´ì¥ ë¡œì§
    if all_records:
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
            writer.writeheader()
            writer.writerows(all_records)
        print(f"ğŸ’¾ [ìµœì¢…] {len(all_records)}ê±´ì˜ ë°ì´í„°ë¥¼ '{file_name}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤!", flush=True)
    else:
        print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒë¼ë¯¸í„°ë¥¼ ë‹¤ì‹œ ì ê²€í•´ì•¼ í•©ë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    fetch_eu_data_hub_fixed()
