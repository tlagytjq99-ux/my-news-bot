import requests
import csv
import os
import time

def fetch_eu_core_policy_only():
    api_url = "https://data.europa.eu/api/hub/search/search"
    
    # 2025ë…„ ë°ì´í„° ìš”ì²­ íŒŒë¼ë¯¸í„°
    params = {
        "filters": "catalogue,dataset,resource",
        "dataScope": "eu",
        "dateType": "issued",
        "minDate": "2025-01-01T00:00:00.000Z",
        "maxDate": "2025-12-31T23:59:59.000Z",
        "includes": "id,title.en,description.en,issued,publisher", # publisher ì •ë³´ ì¶”ê°€
        "limit": 100,
        "page": 0
    }

    file_name = 'EU_Policy_2025_Full.csv'
    all_records = []
    
    # [í•µì‹¬] ìš°ë¦¬ê°€ ì‹ ë¢°í•˜ëŠ” EU ë³¸ë¶€ ê¸°ê´€ í‚¤ì›Œë“œ (ì—¬ê¸°ì— í•´ë‹¹í•´ì•¼ ìˆ˜ì§‘)
    core_publishers = [
        "European Commission", 
        "European Parliament", 
        "Council of the European Union", 
        "European External Action Service",
        "European Environment Agency",
        "Publications Office of the European Union",
        "Eurostat" # í†µê³„ì§€ë§Œ EU ì „ì²´ í†µê³„ì´ë¯€ë¡œ í¬í•¨
    ]

    print("ğŸ›ï¸ EU ë³¸ë¶€(Commission ë“±) ë°œí–‰ ì •ì±… ë°ì´í„°ë§Œ ì„ ë³„ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)

    while True:
        try:
            response = requests.get(api_url, params=params, timeout=30)
            if response.status_code != 200:
                break
            
            data = response.json()
            results = data.get('result', {}).get('results', [])
            
            if not results:
                break
            
            for item in results:
                # ë°œí–‰ì ì •ë³´ í™•ì¸
                publisher_info = item.get('publisher', {})
                publisher_name = str(publisher_info.get('label', ''))
                
                # [í•„í„° ë¡œì§] ë°œí–‰ì ì´ë¦„ì— í•µì‹¬ EU ê¸°ê´€ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
                is_core_eu = any(org in publisher_name for org in core_publishers)
                
                # ì´íƒˆë¦¬ì•„ ë“± êµ­ê°€ê¸°ê´€(ì˜ˆ: ISTAT, Ministry of...)ì€ ì—¬ê¸°ì„œ ê±¸ëŸ¬ì§
                if is_core_eu:
                    title = item.get('title', {}).get('en', 'No English Title')
                    issued_date = item.get('issued', 'N/A')
                    doc_id = item.get('id', '')
                    link = f"https://data.europa.eu/data/datasets/{doc_id}?locale=en"
                    
                    all_records.append({
                        "date": issued_date[:10],
                        "title": title,
                        "link": link
                    })
            
            print(f"ğŸ“¦ í˜„ì¬ í˜ì´ì§€: {params['page']}, í•„í„°ë§ í›„ ëˆ„ì : {len(all_records)}ê±´", flush=True)
            
            params['page'] += 1
            time.sleep(0.1)

            # ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¼ì •ëŸ‰ ìˆ˜ì§‘ ì‹œ ì¤‘ë‹¨í•˜ê³  ì‹¶ë‹¤ë©´ 
            # ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”. (ì „ìˆ˜ì¡°ì‚¬ì‹œëŠ” ì£¼ì„ ìœ ì§€)
            # if params['page'] > 50: break 

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}", flush=True)
            break

    # CSV ì €ì¥
    if all_records:
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
            writer.writeheader()
            writer.writerows(all_records)
        print(f"ğŸ¯ ì„ ë³„ ìˆ˜ì§‘ ì„±ê³µ! ì´ {len(all_records)}ê±´ì˜ EU ë³¸ë¶€ ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    fetch_eu_core_policy_only()
