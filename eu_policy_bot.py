import requests
import csv
import re
from datetime import datetime

def fetch_eu_policy_smart_filter():
    # EUì˜ ìµœì‹  ë°œí–‰ë¬¼ ì „ì²´ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€
    target_url = "https://op.europa.eu/en/web/general-publications/publications"
    file_name = 'EU_Policy_Latest_Reports.csv'
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}

    print("ğŸ“¡ [ì§€ëŠ¥í˜• ìˆ˜ì§‘] í‚¤ì›Œë“œ ì—†ì´ ì•Œì§œ ì •ì±… ë³´ê³ ì„œë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤...", flush=True)

    try:
        response = requests.get(target_url, headers=headers, timeout=30)
        # ëª¨ë“  ë§í¬ì™€ ì œëª© ì¶”ì¶œ
        links = re.findall(r'<a[^>]+href="([^"]+)"[^>]*>(.*?)</a>', response.text)
        
        final_list = []
        seen_titles = set()
        
        # 1. 'ì§„ì§œ' ì •ì±… ë¬¸ì„œì—ë§Œ ë“¤ì–´ê°€ëŠ” í•µì‹¬ ë‹¨ì–´ë“¤ (í¬í•¨ ì¡°ê±´)
        policy_keywords = ['report', 'study', 'strategy', 'briefing', 'policy', 'analysis', 'guide', 'handbook', 'summary', 'commission']
        
        # 2. ì œê±°í•  ì¡ìŒ ë°ì´í„° (ì œì™¸ ì¡°ê±´)
        exclude_list = ['privacy policy', 'legal notice', 'cookies', 'contact', 'sitemap', 
                        'search', 'browse by', 'call us', 'meet us', 'options', 'publishing services']

        for l, t in links:
            title = re.sub('<[^<]+?>', '', t).strip()
            title_lower = title.lower()
            
            # í•„í„°ë§ ì¡°ê±´:
            # - ì œëª©ì´ 30ì ì´ìƒ (ì¶©ë¶„í•œ ì •ë³´ê°€ ë‹´ê¸´ ì œëª©)
            # - ìœ„ ì •ì±… í•µì‹¬ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨
            # - ì œì™¸ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ë‹¨ì–´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
            if len(title) > 30 and title not in seen_titles:
                is_policy = any(pk in title_lower for pk in policy_keywords)
                is_noise = any(ex in title_lower for ex in exclude_list)
                
                if is_policy and not is_noise:
                    full_link = l if l.startswith('http') else "https://op.europa.eu" + l
                    final_list.append({
                        "date": datetime.now().strftime("%Y-%m-%d"),
                        "title": title,
                        "link": full_link
                    })
                    seen_titles.add(title)

        if final_list:
            with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                writer.writeheader()
                writer.writerows(final_list)
            
            print("\n" + "ğŸš€"*20)
            print(f"ğŸ“ í•„í„°ë§ ì™„ë£Œ! {len(final_list)}ê±´ì˜ í•µì‹¬ ì •ì±… ë¬¸ì„œë¥¼ ì„ ë³„í–ˆìŠµë‹ˆë‹¤.")
            print("ğŸš€"*20)
            for i, item in enumerate(final_list[:15], 1): # ìƒìœ„ 15ê°œ ì¶œë ¥
                print(f"{i}. {item['title']}")
                print(f"   ğŸ”— {item['link']}\n")
            print("ğŸš€"*20)
        else:
            print("âš ï¸ ì •ì±… ë¬¸ì„œ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì • ì¤‘ì…ë‹ˆë‹¤...", flush=True)

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

if __name__ == "__main__":
    fetch_eu_policy_smart_filter()
