import requests
import csv
import os

def fetch_eu_cellar_final_push():
    sparql_url = "https://publications.europa.eu/webapi/rdf/sparql"
    
    # [ì „ëµ ë³€ê²½] ë‚ ì§œ í•„í„°ë¥¼ ì•„ì˜ˆ ì œê±°í•˜ê³ , ìµœì‹  ë°œí–‰ ë¬¸ì„œ 1000ê°œë¥¼ ë¬´ì¡°ê±´ ê°€ì ¸ì˜µë‹ˆë‹¤.
    query = """
    PREFIX cdm: <http://publications.europa.eu/ontology/cdm#>
    
    SELECT DISTINCT ?work ?title ?date
    WHERE {
      ?work cdm:work_date_document ?date .
      ?work cdm:work_has_expression ?expr .
      ?expr cdm:expression_title ?title .
      ?expr cdm:expression_uses_language <http://publications.europa.eu/resource/authority/language/ENG> .
    }
    ORDER BY DESC(?date)
    LIMIT 1000
    """

    file_name = 'EU_Policy_2025_Full.csv'
    headers = {
        "Accept": "application/sparql-results+json",
        "User-Agent": "Mozilla/5.0"
    }

    print("ğŸ£ [ìµœì‹ ìˆœ ì „ìˆ˜ ìˆ˜ì§‘] DBì—ì„œ ìµœì‹  ë°ì´í„° 1,000ê±´ì„ í†µì§¸ë¡œ ê²¬ì¸í•©ë‹ˆë‹¤...", flush=True)

    try:
        response = requests.get(sparql_url, params={'query': query}, headers=headers, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            results = data.get('results', {}).get('bindings', [])
            
            all_records = []
            for item in results:
                date_val = item['date']['value']
                # [í•„í„°] ê°€ì ¸ì˜¨ ë°ì´í„° ì¤‘ 2025ë…„ì´ í¬í•¨ëœ ê²ƒë§Œ ê³¨ë¼ ë‹´ê¸°
                if "2025" in date_val:
                    work_uri = item['work']['value']
                    cellar_id = work_uri.split('/')[-1]
                    title = item['title']['value']
                    
                    link = f"https://op.europa.eu/en/publication-detail/-/publication/{cellar_id}"
                    
                    all_records.append({
                        "date": date_val,
                        "title": title,
                        "link": link
                    })
            
            if all_records:
                with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                    writer.writeheader()
                    writer.writerows(all_records)
                print(f"ğŸ¯ [ì„±ê³µ] 2025ë…„ ë°ì´í„° {len(all_records)}ê±´ì„ ì„ ë³„í•˜ì—¬ ì €ì¥í–ˆìŠµë‹ˆë‹¤!", flush=True)
            else:
                # ì—¬ê¸°ê¹Œì§€ ì™”ëŠ”ë° 0ê±´ì´ë©´ DBì— ê¸°ë¡ëœ ìµœì‹  ë‚ ì§œê°€ ì–¸ì œì¸ì§€ í™•ì¸í•´ë´…ë‹ˆë‹¤.
                latest_date = results[0]['date']['value'] if results else "ë°ì´í„° ì—†ìŒ"
                print(f"âš ï¸ 2025ë…„ ë°ì´í„°ê°€ ì„ ë³„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (DB ìµœì‹  ë‚ ì§œ ìƒ˜í”Œ: {latest_date})", flush=True)
        else:
            print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}", flush=True)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

if __name__ == "__main__":
    fetch_eu_cellar_final_push()
