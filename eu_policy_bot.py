import requests
import csv
import os
import time

def fetch_eu_publications_2025_all():
    api_url = "https://data.europa.eu/api/hub/search/search"
    
    params = {
        "filters": "catalogue:cellar", 
        "dataScope": "eu",
        "dateType": "issued",
        "minDate": "2025-01-01T00:00:00.000Z",
        "maxDate": "2025-12-31T23:59:59.000Z",
        "includes": "id,title.en,issued",
        "limit": 100,
        "page": 0
    }

    file_name = 'EU_Policy_2025_Full.csv'
    all_publications = []
    
    print(f"ğŸš€ [ì‹œì‘] 2025ë…„ ë°ì´í„° ìˆ˜ì§‘ì„ ê°€ë™í•©ë‹ˆë‹¤. (íŒŒì¼ëª…: {file_name})", flush=True)

    try:
        while True:
            response = requests.get(api_url, params=params, timeout=30)
            if response.status_code != 200:
                print(f"âš ï¸ API ì‘ë‹µ ì´ìƒ: {response.status_code}", flush=True)
                break
            
            data = response.json()
            results = data.get('result', {}).get('results', [])
            
            if not results:
                print("ğŸ ë” ì´ìƒ ê°€ì ¸ì˜¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", flush=True)
                break
            
            for item in results:
                title = item.get('title', {}).get('en', 'No English Title')
                issued_date = item.get('issued', 'N/A')
                doc_id = item.get('id', '')
                link = f"https://data.europa.eu/data/datasets/{doc_id}?locale=en"
                
                all_publications.append({
                    "date": issued_date[:10],
                    "title": title,
                    "link": link
                })
            
            print(f"ğŸ“¦ í˜„ì¬ {len(all_publications)}ê±´ í™•ë³´ ì¤‘... (í˜ì´ì§€ {params['page'] + 1})", flush=True)
            
            # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë„ˆë¬´ ë§ì´ ëŒì§€ ì•Šë„ë¡ ì„ì‹œ ì œí•œ (ì„±ê³µ í™•ì¸ìš©)
            if params['page'] >= 10: 
                print("ğŸ’¡ í…ŒìŠ¤íŠ¸ ìˆ˜ì§‘ í•œë„(10í˜ì´ì§€) ë„ë‹¬. ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.", flush=True)
                break
                
            params['page'] += 1
            time.sleep(0.2)

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}", flush=True)

    # [ì €ì¥ ë¡œì§ ê°•í™”]
    if all_publications:
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
            writer.writeheader()
            writer.writerows(all_publications)
        
        # íŒŒì¼ì´ ì‹¤ì œë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì²´í¬
        if os.path.exists(file_name):
            print(f"âœ… [ì„±ê³µ] {file_name} íŒŒì¼ì´ {os.path.getsize(file_name)} ë°”ì´íŠ¸ í¬ê¸°ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!", flush=True)
        else:
            print(f"âŒ [ì‹¤íŒ¨] íŒŒì¼ ì“°ê¸°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", flush=True)
    else:
        print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ì–´ íŒŒì¼ì„ ë§Œë“¤ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)

if __name__ == "__main__":
    fetch_eu_publications_2025_all()
