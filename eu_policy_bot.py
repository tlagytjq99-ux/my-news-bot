import requests
import csv
import os

def fetch_eu_cellar_ultimate():
    sparql_url = "https://publications.europa.eu/webapi/rdf/sparql"
    
    # [ì „ëµ] ë°œí–‰ì¼(date_document) ëŒ€ì‹  ìƒì„±ì¼(date_creation)ê³¼ ìˆ˜ì •ì¼(last_modification)ì„ ëª¨ë‘ í™•ì¸í•©ë‹ˆë‹¤.
    query = """
    PREFIX cdm: <http://publications.europa.eu/ontology/cdm#>
    PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>

    SELECT DISTINCT ?work ?title ?date
    WHERE {
      # 1. ìƒì„±ì¼ ë˜ëŠ” ë°œí–‰ì¼ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ê°€ì ¸ì˜´
      { ?work cdm:work_date_creation ?date . }
      UNION
      { ?work cdm:work_date_document ?date . }
      
      ?work cdm:work_has_expression ?expr .
      ?expr cdm:expression_title ?title .
      ?expr cdm:expression_uses_language <http://publications.europa.eu/resource/authority/language/ENG> .
      
      # 2025ë…„ ë°ì´í„° í•„í„°ë§
      FILTER (regex(str(?date), "2025"))
    }
    ORDER BY DESC(?date)
    LIMIT 1000
    """

    file_name = 'EU_Policy_2025_Full.csv'
    headers = {
        "Accept": "application/sparql-results+json",
        "User-Agent": "Mozilla/5.0"
    }

    print("ğŸ•µï¸ [ì‹¬ì¸µ ì¶”ì ] Cellarì˜ ëª¨ë“  ë‚ ì§œ ê¸°ë¡ì„ ë’¤ì ¸ 2025ë…„ ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤...", flush=True)

    try:
        response = requests.get(sparql_url, params={'query': query}, headers=headers, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            results = data.get('results', {}).get('bindings', [])
            
            all_records = []
            for item in results:
                work_uri = item['work']['value']
                cellar_id = work_uri.split('/')[-1]
                title = item['title']['value']
                date_val = item['date']['value']
                
                link = f"https://op.europa.eu/en/publication-detail/-/publication/{cellar_id}"
                
                all_records.append({
                    "date": date_val,
                    "title": title,
                    "link": link
                })
            
            if all_records:
                with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                    writer.writeheader()
                    writer.writerows(all_records)
                print(f"ğŸ¯ [ì„±ê³µ] ë“œë””ì–´ 2025ë…„ ë°ì´í„° {len(all_records)}ê±´ì„ ì°¾ì•„ëƒˆìŠµë‹ˆë‹¤!", flush=True)
            else:
                print("âš ï¸ ëª¨ë“  ë‚ ì§œ í•„ë“œë¥¼ ë’¤ì¡Œìœ¼ë‚˜ 2025ë…„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. DB ì¸ë±ì‹± ì§€ì—° ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.", flush=True)
        else:
            print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code} - {response.text[:100]}", flush=True)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

if __name__ == "__main__":
    fetch_eu_cellar_ultimate()
