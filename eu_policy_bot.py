import requests
import csv
import re

def fetch_eu_robust_scraping():
    # ìµœì‹  ë¬¸ì„œ í”¼ë“œ ì£¼ì†Œ
    feed_url = "https://op.europa.eu/en/web/general-publications/publications?p_p_id=eu_europa_publications_portlet_search_search_results_display_WAR_eu_europa_publications_portlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_eu_europa_publications_portlet_search_search_results_display_WAR_eu_europa_publications_portlet_format=rss"
    
    file_name = 'EU_Policy_2025_Final.csv'
    all_records = []
    
    print("ğŸ§¹ [ê°•ë ¥ ìˆ˜ì§‘] ê¹¨ì§„ ê¸€ìë¥¼ ë¬´ì‹œí•˜ê³  2025ë…„ ì •ì±… ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...", flush=True)

    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(feed_url, headers=headers, timeout=30)
        response.encoding = 'utf-8' # ì¸ì½”ë”© ê°•ì œ ì„¤ì •

        # XML íŒŒì‹± ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ 'ì •ê·œí‘œí˜„ì‹'ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
        # <title>ê³¼ <link> íƒœê·¸ ì‚¬ì´ì— ìˆëŠ” ê¸€ìë“¤ì„ ì§ì ‘ ë‚šì•„ì±•ë‹ˆë‹¤.
        content = response.text
        titles = re.findall(r'<title>(.*?)</title>', content, re.DOTALL)
        links = re.findall(r'<link>(.*?)</link>', content, re.DOTALL)
        
        # ì²« ë²ˆì§¸ ì œëª©ì€ ì±„ë„ ì •ë³´ì´ë¯€ë¡œ ì œì™¸í•˜ê³  1ëŒ€1 ë§¤ì¹­
        for t, l in zip(titles[1:], links[1:]):
            # CDATA íƒœê·¸ ë“± ë¶ˆí•„ìš”í•œ ì¥ì‹ ì œê±°
            clean_title = t.replace('<![CDATA[', '').replace(']]>', '').strip()
            clean_link = l.strip()
            
            # ì œëª©ì— 2025ê°€ ìˆê±°ë‚˜ ìµœì‹  ë¬¸ì„œë¼ë©´ ìˆ˜ì§‘
            # RSS í”¼ë“œ íŠ¹ì„±ìƒ ìµœê·¼ 1ê°œì›” ë‚´ ë¬¸ì„œê°€ ì£¼ë¡œ ì˜¬ë¼ì˜µë‹ˆë‹¤.
            all_records.append({
                "date": "2025-Latest",
                "title": clean_title,
                "link": clean_link
            })

        if all_records:
            with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                writer.writeheader()
                writer.writerows(all_records)
            print(f"âœ… [ì„±ê³µ] ì´ {len(all_records)}ê±´ì˜ ìµœì‹  ì •ì±… ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤!", flush=True)
            print(f"ğŸ“Œ ì²« ë²ˆì§¸ ë°ì´í„° í™•ì¸: {all_records[0]['title'][:50]}...", flush=True)
        else:
            print("âš ï¸ íšë“í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ì˜ ì‘ë‹µ í˜•ì‹ì„ ë‹¤ì‹œ ì ê²€í•©ë‹ˆë‹¤.", flush=True)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", flush=True)

if __name__ == "__main__":
    fetch_eu_robust_scraping()
