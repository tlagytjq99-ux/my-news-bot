import requests
from bs4 import BeautifulSoup
import csv
import os
from datetime import datetime
from urllib.parse import urljoin

def main():
    # ğŸ¯ íƒ€ê²Ÿ: ë‚´ê°ë¶€ ë³´ë„ë°œí‘œ(News Release) ì „ìš© í˜ì´ì§€
    # ì´ê³³ì€ êµ¬ì¡°ê°€ ë¹„êµì  ì¼ì •í•´ì„œ ë‰´ìŠ¤ë§Œ ê³¨ë¼ë‚´ê¸° ì¢‹ìŠµë‹ˆë‹¤.
    target_url = "https://www.cao.go.jp/houdou/houdou.html"
    file_name = 'japan_ai_report.csv'
    
    print(f"ğŸ“¡ [ì¼ë³¸ ë‚´ê°ë¶€] ë³´ë„ìë£Œ ì •ë°€ ìˆ˜ì§‘ ì‹œì‘...")

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
    }

    try:
        response = requests.get(target_url, headers=headers, timeout=20)
        response.encoding = 'utf-8' 
        soup = BeautifulSoup(response.text, 'html.parser')

        # ğŸ’¡ [í•µì‹¬] ë‰´ìŠ¤ ì•„ì´í…œì€ ë³´í†µ 'main_list' í´ë˜ìŠ¤ì˜ <li> ì•ˆì— ìˆìŠµë‹ˆë‹¤.
        # í˜¹ì€ <dt>(ë‚ ì§œ) <dd>(ì œëª©) êµ¬ì¡°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        new_data = []
        existing_titles = set()
        if os.path.exists(file_name):
            with open(file_name, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                for row in reader: existing_titles.add(row['ì œëª©'])

        # ë‰´ìŠ¤ ë³¸ë¬¸ ì˜ì—­ ì°¾ê¸°
        content_area = soup.find('div', id='main_list') or soup.find('div', id='contents')
        
        if content_area:
            # ğŸ’¡ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ì˜ <a> íƒœê·¸ë“¤ë§Œ ì¶”ì¶œ
            items = content_area.find_all('a', href=True)
            
            count = 0
            for a in items:
                title = a.get_text().strip()
                link = urljoin(target_url, a['href'])
                
                # ğŸ’¡ [í•„í„°ë§]
                # 1. ì œëª©ì— 'ë‚´ê°ë¶€' ê°™ì€ ë‹¨ìˆœ ì‚¬ì´íŠ¸ëª… ì œì™¸
                # 2. ì´ë¯¸ ìˆ˜ì§‘í•œ ì œëª© ì œì™¸
                # 3. ì£¼ì†Œì— houdou(ë³´ë„)ë‚˜ ê¸°ì‚¬ í˜•ì‹ì´ í¬í•¨ëœ ê²ƒ
                if len(title) > 15 and title not in existing_titles:
                    if 'index.html' not in link[-10:]: # ë‹¨ìˆœ ë©”ì¸í˜ì´ì§€ ë§í¬ ì œì™¸
                        
                        print(f"   ğŸ†• ë‰´ìŠ¤ ë°œê²¬: {title[:40]}...")
                        new_data.append({
                            "ê¸°ê´€": "ì¼ë³¸ ë‚´ê°ë¶€(CAO)",
                            "ë°œí–‰ì¼": datetime.now().strftime("%Y-%m-%d"),
                            "ì œëª©": title,
                            "ë§í¬": link,
                            "ìˆ˜ì§‘ì¼": datetime.now().strftime("%Y-%m-%d")
                        })
                        count += 1
                        if count >= 5: break

        # ğŸ’¾ ê²°ê³¼ ì €ì¥
        if new_data:
            file_exists = os.path.exists(file_name)
            with open(file_name, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ë§í¬", "ìˆ˜ì§‘ì¼"])
                if not file_exists: writer.writeheader()
                writer.writerows(new_data)
            print(f"âœ… ì„±ê³µ! {len(new_data)}ê±´ì˜ ë³´ë„ìë£Œ ìˆ˜ì§‘ ì™„ë£Œ.")
        else:
            print("âŒ ì‹¤ì œ ë‰´ìŠ¤ ì˜ì—­ì„ ì°¾ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íƒ€ê²Ÿì„ ë‹¤ì‹œ ì¡°ì •í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
