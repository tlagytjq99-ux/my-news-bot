import requests
from bs4 import BeautifulSoup
import csv
import os
from datetime import datetime
from urllib.parse import urljoin

def main():
    # ğŸ¯ íƒ€ê²Ÿ: ë‚´ê°ë¶€ ì „ì²´ ì‹ ì°© ì •ë³´ (ê°€ì¥ ë°ì´í„°ê°€ ë§ì€ í˜ì´ì§€)
    target_url = "https://www.cao.go.jp/new/index.html"
    file_name = 'japan_ai_report.csv'
    
    print(f"ğŸ“¡ [ì¼ë³¸ ë‚´ê°ë¶€] AI í‚¤ì›Œë“œ íƒìƒ‰ ëª¨ë“œ ê°€ë™...")

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
    }

    try:
        response = requests.get(target_url, headers=headers, timeout=20)
        response.encoding = response.apparent_encoding 
        soup = BeautifulSoup(response.text, 'html.parser')

        # 1. í˜ì´ì§€ ë‚´ ëª¨ë“  ë§í¬(a)ë¥¼ ë‹¤ ê¸ì–´ëª¨ìë‹ˆë‹¤.
        links = soup.find_all('a', href=True)
        
        new_data = []
        existing_titles = set()
        if os.path.exists(file_name):
            with open(file_name, 'r', encoding='utf-8-sig') as f:
                reader = csv.DictReader(f)
                for row in reader: existing_titles.add(row['ì œëª©'])

        # ğŸ’¡ [í•µì‹¬] ì¼ë³¸ ì •ë¶€ê°€ AI ì •ì±…ì— ì“°ëŠ” í•µì‹¬ ë‹¨ì–´ë“¤
        # äººå·¥çŸ¥èƒ½(ì¸ê³µì§€ëŠ¥), æˆ¦ç•¥(ì „ëµ), ãƒ‡ã‚¸ã‚¿ãƒ«(ë””ì§€í„¸), å ±å‘Š(ë³´ê³ ), æ±ºå®š(ê²°ì •)
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ AIê°€ í¬í•¨ëœ 'ì „ëµ'ì´ë‚˜ 'ê¸°ìˆ ' í‚¤ì›Œë“œë„ í¬í•¨í•©ë‹ˆë‹¤.
        ai_keywords = ['AI', 'äººå·¥çŸ¥èƒ½', 'æˆ¦ç•¥', 'æŠ€è¡“', 'ãƒ‡ã‚¸ã‚¿ãƒ«', 'ä¼šè­°']

        count = 0
        for a in links:
            title = a.get_text().strip()
            link = urljoin(target_url, a['href'])
            
            # 2. í•„í„°ë§: ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆê³ , ë„ˆë¬´ ì§§ì§€ ì•Šìœ¼ë©°, ì¤‘ë³µì´ ì•„ë‹ ë•Œ
            if any(kw in title.upper() for kw in ai_keywords):
                if len(title) > 10 and title not in existing_titles:
                    
                    # ì¼ë³¸ ì‚¬ì´íŠ¸ íŠ¹ìœ ì˜ ë‚ ì§œ íŒ¨í„´ì„ ì œëª©ì—ì„œ ì°¾ê±°ë‚˜ ì˜¤ëŠ˜ ë‚ ì§œ ì‚¬ìš©
                    print(f"   ğŸ†• ìƒˆ ì •ì±… ì†Œì‹ ë°œê²¬: {title[:40]}...")
                    new_data.append({
                        "ê¸°ê´€": "ì¼ë³¸ ë‚´ê°ë¶€(CAO)",
                        "ë°œí–‰ì¼": datetime.now().strftime("%Y-%m-%d"),
                        "ì œëª©": title,
                        "ë§í¬": link,
                        "ìˆ˜ì§‘ì¼": datetime.now().strftime("%Y-%m-%d")
                    })
                    count += 1
                    if count >= 5: break

        # ğŸ’¾ ê²°ê³¼ ì €ì¥
        if new_data:
            file_exists = os.path.exists(file_name)
            with open(file_name, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ë§í¬", "ìˆ˜ì§‘ì¼"])
                if not file_exists: writer.writeheader()
                writer.writerows(new_data)
            print(f"âœ… ì„±ê³µ! ì¼ë³¸ AI ê´€ë ¨ ë°ì´í„° {len(new_data)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ.")
        else:
            print("ğŸ’¡ í˜„ì¬ ì¼ë³¸ ë‚´ê°ë¶€ ìµœì‹  ì†Œì‹ ì¤‘ AI ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
