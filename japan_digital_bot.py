import requests
import re
import csv
import urllib3

# SSL ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def crawl_digital_agency_final_attempt():
    file_name = 'Japan_Digital_Policy_2025.csv'
    # ì›ë³¸ URLë¡œ ë³µê·€í•˜ë˜, SSL ê²€ì¦ì„ ë•ë‹ˆë‹¤.
    url = "https://www.digital.go.jp/press?category=1"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'ja-JP,ja;q=0.9,ko-KR;q=0.8,ko;q=0.7,en-US;q=0.6,en;q=0.5',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache',
    }

    print(f"ğŸš€ [ìµœì¢… ë³´ì • ëª¨ë“œ] SSL ê²€ì¦ì„ ìš°íšŒí•˜ì—¬ {url}ì— ì ‘ì†í•©ë‹ˆë‹¤...")

    try:
        # verify=Falseë¡œ SSL ì¸ì¦ì„œ ì—ëŸ¬ë¥¼ ê°•ì œë¡œ í†µê³¼í•©ë‹ˆë‹¤.
        response = requests.get(url, headers=headers, timeout=30, verify=False)
        html_content = response.text
        
        # ì •ê·œí‘œí˜„ì‹: /press/ ë’¤ì— ì˜ë¬¸/ìˆ«ì/ëŒ€ì‹œê°€ ë¶™ì€ ëª¨ë“  ë§í¬ ì¶”ì¶œ
        # <a ... href="/press/xxxx"> ì œëª© </a> í˜•íƒœ íƒ€ê²ŸíŒ…
        pattern = r'href="(/press/[^"]+)"[^>]*>(.*?)</a>'
        matches = re.findall(pattern, html_content)

        policy_results = []
        for link, title in matches:
            clean_title = re.sub(r'<[^>]+>', '', title).strip()
            # ë©”ë‰´ë‚˜ ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ í•„í„°ë§
            if len(clean_title) < 10 or "ä¸€è¦§" in clean_title: continue
            
            policy_results.append({
                "date": "2025/2026",
                "title": clean_title,
                "link": "https://www.digital.go.jp" + link if link.startswith('/') else link
            })

        if policy_results:
            unique_data = list({v['link']: v for v in policy_results}.values())
            with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                writer.writeheader()
                writer.writerows(unique_data)
            print(f"âœ… ë“œë””ì–´ ì„±ê³µ! {len(unique_data)}ê±´ì˜ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš ï¸ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ì •ì ì´ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            # ë¹ˆ íŒŒì¼ ìƒì„±
            with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                f.write("date,title,link\n")

    except Exception as e:
        print(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        with open(file_name, 'w', encoding='utf-8-sig') as f:
            f.write("date,title,link\n")

if __name__ == "__main__":
    crawl_digital_agency_final_attempt()
