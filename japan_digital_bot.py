import asyncio
from playwright.async_api import async_playwright
import csv

async def crawl_digital_2025_playwright():
    start_page = 21
    end_page = 188
    file_name = 'Japan_Digital_2025_Full_Archive.csv'
    all_data = []
    seen_links = set()

    async with async_playwright() as p:
        # ë¸Œë¼ìš°ì € ì‹¤í–‰ (headless=TrueëŠ” í™”ë©´ ì•ˆ ë„ì›€)
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page_obj = await context.new_page()

        print(f"ğŸš€ [ë¸Œë¼ìš°ì € ëª¨ë“œ] {start_page} ~ {end_page} í˜ì´ì§€ ì •ë°€ ìŠ¤ìº” ì‹œì‘...")

        for p_num in range(start_page, end_page + 1):
            url = f"https://www.digital.go.jp/news?page={p_num}"
            
            try:
                # í˜ì´ì§€ ì ‘ì† ë° ë¡œë”© ëŒ€ê¸°
                await page_obj.goto(url, wait_until="networkidle", timeout=60000)
                # ë°ì´í„°ê°€ ë¡œë“œë  ë•Œê¹Œì§€ 1ì´ˆ ë” ëŒ€ê¸°
                await asyncio.sleep(1) 

                # í˜ì´ì§€ ë‚´ì˜ ëª¨ë“  ë‰´ìŠ¤ ë§í¬ ì¶”ì¶œ
                # evaluateë¥¼ ì¨ì„œ ë¸Œë¼ìš°ì € ë‚´ë¶€ ìë°”ìŠ¤í¬ë¦½íŠ¸ë¡œ ì§ì ‘ ë§í¬ë¥¼ ë½‘ìŠµë‹ˆë‹¤.
                links = await page_obj.evaluate("""
                    () => {
                        const results = [];
                        const anchors = document.querySelectorAll('a[href*="/news/"], a[href*="/press/"], a[href*="/policies/"]');
                        anchors.forEach(a => {
                            if (a.innerText.length > 15) {
                                results.append({
                                    title: a.innerText.replace(/\\n/g, ' ').trim(),
                                    href: a.href
                                });
                            }
                        });
                        return results;
                    }
                """)

                for link in links:
                    if link['href'] not in seen_links:
                        seen_links.add(link['href'])
                        all_data.append({
                            "title": link['title'],
                            "link": link['href']
                        })
                
                print(f"ğŸ“¡ {p_num}/{end_page} ì™„ë£Œ | ëˆ„ì : {len(all_data)}ê±´", end='\r')

            except Exception as e:
                print(f"\nâŒ {p_num}í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue

        await browser.close()

    # CSV ì €ì¥
    if all_data:
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["title", "link"])
            writer.writeheader()
            writer.writerows(all_data)
        print(f"\n\nâœ… [ì„ë¬´ ì™„ìˆ˜] ì´ {len(all_data)}ê±´ì˜ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("\nâš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(crawl_digital_2025_playwright())
