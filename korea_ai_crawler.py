import feedparser
import csv
import urllib.parse
from datetime import datetime
from googlenewsdecoder import gnewsdecoder

def main():
    target_sources = {
        "ê³¼ê¸°ì •í†µë¶€": 'site:msit.go.kr (ì¸ê³µì§€ëŠ¥ OR AI) -intitle:ì§ì› -intitle:ê²€ìƒ‰',
        "NIA": 'site:nia.or.kr (ì¸ê³µì§€ëŠ¥ OR AI) -intitle:ì´ë™ -intitle:ê³µê³ ',
        "SPRI": 'site:spri.kr (ì¸ê³µì§€ëŠ¥ OR AI)',
        "ê°œì¸ì •ë³´ìœ„": 'site:pipc.go.kr (ì¸ê³µì§€ëŠ¥ OR AI)'
    }

    # ğŸ›‘ ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í‚¤ì›Œë“œ
    exclude_keywords = ['ë§¨ ë’¤ë¡œ', 'ì§ì›ê²€ìƒ‰', 'ì¹´ë“œë‰´ìŠ¤', 'ì…ì°°ê³µê³ ', 'ê²Œì‹œíŒ ì¸ì‡„', 'ë¡œê·¸ì¸', 'í™ˆí˜ì´ì§€']

    file_name = 'korea_ai_policy_clean.csv'
    collected_date = datetime.now().strftime("%Y-%m-%d")
    final_data = []

    for agency, query in target_sources.items():
        encoded_query = urllib.parse.quote(query)
        rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
        feed = feedparser.parse(rss_url)
        
        for entry in feed.entries[:15]: # ë” ë§ì´ í›‘ê³  í•„í„°ë§
            title = entry.title.split(' - ')[0]
            
            # 1. ë…¸ì´ì¦ˆ í•„í„°ë§ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë‹¨ì–´ê°€ ì œëª©ì— ìˆìœ¼ë©´ ì œì™¸)
            if any(key in title for key in exclude_keywords):
                continue
            
            # 2. ë„ˆë¬´ ì§§ì€ ì œëª© ì œì™¸ (ì •ìƒì ì¸ ì œëª©ì€ ë³´í†µ 10ì ì´ìƒ)
            if len(title) < 5:
                continue

            try:
                decoded = gnewsdecoder(entry.link)
                actual_link = decoded.get('decoded_url', entry.link)
            except:
                actual_link = entry.link

            pub_date = datetime(*entry.published_parsed[:6]).strftime('%Y-%m-%d')
            
            # 3. ìµœì‹  ë°ì´í„°ë§Œ ìˆ˜ì§‘ (ì˜ˆ: 2025ë…„ ì´í›„ ë°ì´í„°ë§Œ)
            if pub_date < '2025-01-01':
                continue

            is_pdf = "YES" if "Download" in actual_link or actual_link.lower().endswith('.pdf') or "FileDown" in actual_link else "NO"

            final_data.append({
                "ê¸°ê´€": agency,
                "ë°œí–‰ì¼": pub_date,
                "ì œëª©": f"[ë¦¬í¬íŠ¸] {title}" if is_pdf == "YES" else title,
                "PDFì—¬ë¶€": is_pdf,
                "ë§í¬": actual_link
            })

    # ì €ì¥ ë¡œì§ (ìµœì‹ ìˆœ)
    final_data.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "PDFì—¬ë¶€", "ë§í¬"])
        writer.writeheader()
        writer.writerows(final_data)

if __name__ == "__main__":
    main()
