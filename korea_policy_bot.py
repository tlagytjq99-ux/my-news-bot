import requests
import csv

def fetch_eu_cellar_final_match():
    sparql_url = "https://publications.europa.eu/webapi/rdf/sparql"
    
    # [ìˆ˜ì •] ë‚ ì§œ ê³„ì‚° ëŒ€ì‹  '2025' ë¬¸ìì—´ í¬í•¨ ì—¬ë¶€ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ DBì˜ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜ë¥¼ ì™„ë²½í•˜ê²Œ ë¬´ì‹œí•˜ê³  ë‚šì•„ì±Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    query = """
    PREFIX cdm: <http://publications.europa.eu/ontology/cdm#>
    
    SELECT DISTINCT ?work ?date ?title
    WHERE {
      ?work a cdm:work ;
            cdm:work_date_document ?date ;
            cdm:work_has_expression ?expr .
      ?expr cdm:expression_title ?title .
      ?expr cdm:expression_uses_language <http://publications.europa.eu/resource/authority/language/ENG> .
      
      # ë‚ ì§œ í•„ë“œì— '2025'ê°€ í¬í•¨ëœ ëª¨ë“  ê²ƒì„ ê°€ì ¸ì˜´
      FILTER (contains(str(?date), "2025"))
    }
    ORDER BY DESC(?date)
    LIMIT 100
    """

    file_name = 'EU_Policy_2025_Full.csv'
    headers = {"Accept": "application/sparql-results+json"}

    print("ğŸ¯ [ìµœì¢… íƒ€ê²©] 2025ë…„ ë¬¸ìì—´ ë§¤ì¹­ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°•ì œ ì¶”ì¶œí•©ë‹ˆë‹¤...", flush=True)

    try:
        # POST ë°©ì‹ìœ¼ë¡œ ì¿¼ë¦¬ ì „ì†¡
        response = requests.post(sparql_url, data={'query': query}, headers=headers, timeout=60)
        
        if response.status_code == 200:
            data = response.json()
            bindings = data.get('results', {}).get('bindings', [])
            
            all_records = []
            for item in bindings:
                cellar_url = item['work']['value']
                uuid = cellar_url.split('/')[-1]
                title = item['title']['value']
                date = item['date']['value']
                link = f"https://op.europa.eu/en/publication-detail/-/publication/{uuid}"
                
                all_records.append({
                    "date": date,
                    "title": title,
                    "link": link
                })

            if all_records:
                with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=["date", "title", "link"])
                    writer.writeheader()
                    writer.writerows(all_records)
                print(f"âœ… [ì„±ê³µ] 2025ë…„ ë°ì´í„° {len(all_records)}ê±´ì„ ë“œë””ì–´ ì°¾ì•„ëƒˆìŠµë‹ˆë‹¤!", flush=True)
            else:
                # 2025ë…„ì´ ì •ë§ ì—†ë‹¤ë©´ 2024ë…„ì´ë¼ë„ ìˆëŠ”ì§€ í™•ì¸í•˜ì—¬ ì„œë²„ ìƒíƒœ ìµœì¢… ì ê²€
                print("âš ï¸ 2025ë…„ ë§¤ì¹­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. DB ì¸ë±ì‹± ì§€ì—°ì´ í™•ì‹¤í•´ ë³´ì…ë‹ˆë‹¤.", flush=True)
        else:
            print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}", flush=True)

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}", flush=True)

if __name__ == "__main__":
    fetch_eu_cellar_final_match()
