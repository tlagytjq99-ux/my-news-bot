import asyncio
import csv
from datetime import datetime
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig

async def main():
    # ìˆ˜ì§‘í•  AI ë‰´ìŠ¤ ì‚¬ì´íŠ¸ (êµ¬ì¡°ê°€ ê·¸ë‚˜ë§ˆ í‘œì¤€ì ì¸ ê³³ë“¤)
    urls = [
        "https://www.aitimes.com/news/articleList.html?sc_section_code=S1N1",
        "https://venturebeat.com/category/ai/",
        "https://www.artificialintelligence-news.com/"
    ]

    final_results = []
    today_str = datetime.now().strftime("%Y-%m-%d")

    # ë¸Œë¼ìš°ì € ì„¤ì •: ì§„ì§œ ì‚¬ëŒì²˜ëŸ¼ ìœ„ì¥
    browser_config = BrowserConfig(
        headless=True,
        user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )

    async with AsyncWebCrawler(config=browser_config) as crawler:
        for url in urls:
            print(f"ğŸ“¡ {url} ì ‘ì† ì‹œë„ ì¤‘...")
            
            # ë³µì¡í•œ ê·œì¹™ ëŒ€ì‹  'ì „ì²´ ë§ˆí¬ë‹¤ìš´'ì„ ê¸ì–´ì™€ì„œ ë¶„ì„í•˜ëŠ” ë°©ì‹
            result = await crawler.arun(url=url, bypass_cache=True)

            if result.success and result.markdown:
                # ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ì—ì„œ [ì œëª©](ë§í¬) í˜•íƒœë¥¼ ì°¾ì•„ë‚´ëŠ” ê°„ë‹¨í•œ ê·œì¹™
                import re
                # ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ë§í¬ íŒ¨í„´ ì¶”ì¶œ
                links = re.findall(r'\[([^\]]{15,})\]\(([^\)]+)\)', result.markdown)
                
                count = 0
                for title, link in links:
                    # ê´‘ê³ ì„± ë§í¬ë‚˜ ì§§ì€ ë©”ë‰´ëŠ” ì œì™¸
                    if any(x in link for x in ['login', 'twitter', 'facebook', 'category', 'author']):
                        continue
                    
                    full_link = link if link.startswith('http') else f"{url.split('/')[0]}//{url.split('/')[2]}{link}"
                    
                    final_results.append({
                        "ìˆ˜ì§‘ì¼": today_str,
                        "ë°œí–‰ì¼": today_str, # ë¬´ë£Œ ë²„ì „ì—ì„œëŠ” ì˜¤ëŠ˜ ë‚ ì§œë¡œ í†µì¼
                        "ì œëª©": title.strip(),
                        "ë§í¬": full_link
                    })
                    count += 1
                    if count >= 5: break
                
                print(f"âœ… {url}: {count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    # ê²°ê³¼ ì €ì¥
    with open('ai_trend_report.csv', 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["ìˆ˜ì§‘ì¼", "ë°œí–‰ì¼", "ì œëª©", "ë§í¬"])
        writer.writeheader()
        if final_results:
            writer.writerows(final_results)
        else:
            writer.writerow({"ìˆ˜ì§‘ì¼": today_str, "ë°œí–‰ì¼": "-", "ì œëª©": "ì—¬ì „íˆ ìˆ˜ì§‘ ì‹¤íŒ¨. ì‚¬ì´íŠ¸ ë³´ì•ˆì´ ê°•ë ¥í•©ë‹ˆë‹¤.", "ë§í¬": "-"})

if __name__ == "__main__":
    asyncio.run(main())
