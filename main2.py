import asyncio
import csv
from datetime import datetime
from urllib.parse import urljoin
from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig

async def main():
    # ğŸ”— ê´€ë¦¬í•  ì •ë³´ì› ë¦¬ìŠ¤íŠ¸ (ì—¬ê¸°ì— ê³„ì† ì¶”ê°€í•˜ì‹œë©´ ë©ë‹ˆë‹¤)
    target_sites = {
        "AIíƒ€ì„ìŠ¤": "https://www.aitimes.com/news/articleList.html?sc_section_code=S1N1",
        "ë²¤ì²˜ë¹„íŠ¸": "https://venturebeat.com/category/ai/",
        "í…Œí¬í¬ëŸ°ì¹˜": "https://techcrunch.com/category/artificial-intelligence/",
        "AIë‰´ìŠ¤(ì˜êµ­)": "https://www.artificialintelligence-news.com/",
        "ë³´ì•ˆë‰´ìŠ¤": "https://www.boannews.com/media/list.asp?mkind=1"
    }

    browser_config = BrowserConfig(browser_type="chromium", headless=True)
    run_config = CrawlerRunConfig(wait_for="h2, h3, a", wait_for_timeout=15000)
    
    final_data = []
    today = datetime.now().strftime("%Y-%m-%d")
    exclude_keywords = ["ë°”ë¡œê°€ê¸°", "ë¡œê·¸ì¸", "íšŒì›ê°€ì…", "copyright", "terms"]

    async with AsyncWebCrawler(config=browser_config) as crawler:
        # ì •ë³´ì›ì´ ë§ì•„ì§€ë©´ í•˜ë‚˜ì”©(Forë¬¸) ìˆ˜ì§‘í•˜ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.
        for site_name, url in target_sites.items():
            try:
                print(f"ğŸ“¡ [{site_name}] ìˆ˜ì§‘ ì¤‘...")
                result = await crawler.arun(url=url, config=run_config)

                if result.success and result.markdown:
                    import re
                    # ë‰´ìŠ¤ ì œëª©ì€ ë³´í†µ 20ì ì´ìƒì¸ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.
                    links = re.findall(r'\[([^\]]{20,})\]\(([^\)]+)\)', result.markdown)
                    
                    added = 0
                    for title, link in links:
                        title_clean = title.strip()
                        if any(kw in title_clean.lower() for kw in exclude_keywords): continue
                        
                        full_link = urljoin(url, link)
                        final_data.append({
                            "ì¶œì²˜": site_name,
                            "ìˆ˜ì§‘ì¼": today,
                            "ì œëª©": title_clean,
                            "ë§í¬": full_link
                        })
                        added += 1
                        if added >= 5: break # ì‚¬ì´íŠ¸ë‹¹ 5ê°œì”©ë§Œ
                    print(f"âœ… {site_name}: {added}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ {site_name} ì—ëŸ¬ ë°œìƒ: {e}")

    # ë°ì´í„° ì €ì¥
    if final_data:
        with open('ai_trend_report.csv', 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ì¶œì²˜", "ìˆ˜ì§‘ì¼", "ì œëª©", "ë§í¬"])
            writer.writeheader()
            writer.writerows(final_data)
        print(f"ğŸ‰ ì´ {len(final_data)}ê°œì˜ ë‰´ìŠ¤ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())
