import requests
from bs4 import BeautifulSoup
import csv
import os
from datetime import datetime
from googletrans import Translator
import time

def main():
    # ğŸ¯ ë§¥í‚¨ì§€(RSS) + PwC ê¸°ìˆ  ì„¹ì…˜(ì§ì ‘ í¬ë¡¤ë§)
    target_url = "https://www.pwc.com/gx/en/issues/technology.html"
    file_name = 'ai_market_intelligence.csv'
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")
    
    print(f"ğŸ“¡ [PwC ê¸°ìˆ ì„¹ì…˜] ì§ì ‘ ê³µëµ ìˆ˜ì§‘ ì‹œì‘...")

    new_data = []

    # 1ï¸âƒ£ [McKinsey ìˆ˜ì§‘] - ê¸°ì¡´ì— ì˜ ë˜ë˜ ë°©ì‹ ìœ ì§€
    try:
        import feedparser
        mck_feed = feedparser.parse("https://www.mckinsey.com/insights/rss")
        for entry in mck_feed.entries[:10]:
            new_data.append({
                "ê¸°ê´€": "McKinsey",
                "ë°œí–‰ì¼": time.strftime('%Y-%m-%d', entry.published_parsed) if 'published_parsed' in entry else collected_date,
                "ì œëª©": translator.translate(entry.title, dest='ko').text,
                "ì›ë¬¸": entry.title,
                "ë§í¬": entry.link,
                "ìˆ˜ì§‘ì¼": collected_date
            })
        print(f"   âœ… McKinsey ìˆ˜ì§‘ ì™„ë£Œ")
    except:
        print(f"   âš ï¸ McKinsey ìˆ˜ì§‘ ì¤‘ ì¼ë¶€ ì˜¤ë¥˜")

    # 2ï¸âƒ£ [PwC ì§ì ‘ ê³µëµ] - ëŒ€í‘œë‹˜ì´ ì£¼ì‹  í˜ì´ì§€ë¥¼ ëš«ìŠµë‹ˆë‹¤.
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Accept-Language": "en-US,en;q=0.9,ko;q=0.8"
    }

    try:
        response = requests.get(target_url, headers=headers, timeout=30)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # PwC í˜ì´ì§€ì˜ ë‰´ìŠ¤ ì¹´ë“œ ì œëª©ê³¼ ë§í¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            # PwCëŠ” ë³´í†µ h3 íƒœê·¸ë‚˜ íŠ¹ì • í´ë˜ìŠ¤ì˜ a íƒœê·¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            articles = soup.find_all(['h3', 'h4', 'a'], limit=50)
            
            pwc_count = 0
            for art in articles:
                title_en = art.get_text().strip()
                # AI, Tech ê´€ë ¨ ê¸€ë§Œ í•„í„°ë§
                if any(kw in title_en.upper() for kw in ['AI', 'TECH', 'DIGITAL', 'GEN', 'INTELLIGENCE']):
                    link = ""
                    if art.name == 'a':
                        link = art.get('href', '')
                    else:
                        parent = art.find_parent('a')
                        if parent: link = parent.get('href', '')

                    if link and len(title_en) > 20:
                        full_url = f"https://www.pwc.com{link}" if link.startswith('/') else link
                        
                        # ì¤‘ë³µ ì œê±° ë° ìˆ˜ì§‘
                        if not any(d['ì›ë¬¸'] == title_en for d in new_data):
                            try:
                                title_ko = translator.translate(title_en, dest='ko').text
                            except:
                                title_ko = title_en

                            new_data.append({
                                "ê¸°ê´€": "PwC",
                                "ë°œí–‰ì¼": collected_date, # í˜ì´ì§€ íŠ¹ì„±ìƒ ë°œí–‰ì¼ ì¶”ì¶œì´ ì–´ë ¤ì›Œ ìˆ˜ì§‘ì¼ë¡œ ëŒ€ì²´
                                "ì œëª©": title_ko,
                                "ì›ë¬¸": title_en,
                                "ë§í¬": full_url,
                                "ìˆ˜ì§‘ì¼": collected_date
                            })
                            pwc_count += 1
                if pwc_count >= 10: break
            print(f"   âœ… PwC ({target_url})ì—ì„œ {pwc_count}ê±´ í™•ë³´!")
        else:
            print(f"   âŒ PwC í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
    except Exception as e:
        print(f"   âŒ PwC ì§ì ‘ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬: {e}")

    # ğŸ’¾ CSV ì €ì¥
    if new_data:
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬", "ìˆ˜ì§‘ì¼"])
            writer.writeheader()
            writer.writerows(new_data)
        print(f"\nğŸ‰ í†µí•© ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(new_data)}ê±´ ì €ì¥.")
    else:
        print("\nğŸ’¡ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
