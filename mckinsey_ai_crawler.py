import requests
from bs4 import BeautifulSoup
import feedparser
import csv
import os
import time
from datetime import datetime
from googletrans import Translator

def main():
    file_name = 'ai_market_intelligence.csv'
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")
    
    print(f"ğŸ“¡ [í†µí•© ì—”ì§„] ìˆ˜ì§‘ ì‹œì‘ (McKinsey + PwC ì •ë°€ íƒ€ê²©)...")
    new_data = []

    # --- [McKinsey: RSS ë°©ì‹] ---
    print(f"ğŸ” McKinsey ë¶„ì„ ì¤‘...")
    try:
        mck_feed = feedparser.parse("https://www.mckinsey.com/insights/rss")
        for entry in mck_feed.entries[:12]:
            try:
                title_ko = translator.translate(entry.title, dest='ko').text
                new_data.append({
                    "ê¸°ê´€": "McKinsey",
                    "ë°œí–‰ì¼": time.strftime('%Y-%m-%d', entry.published_parsed) if 'published_parsed' in entry else collected_date,
                    "ì œëª©": title_ko, "ì›ë¬¸": entry.title, "ë§í¬": entry.link, "ìˆ˜ì§‘ì¼": collected_date
                })
            except:
                continue
        print(f"   âœ… McKinsey í™•ë³´ ì™„ë£Œ")
    except Exception as e:
        print(f"   âš ï¸ McKinsey ì˜¤ë¥˜: {e}")

    # --- [PwC: ê´‘ë²”ìœ„ í…ìŠ¤íŠ¸ ìˆ˜ìƒ‰ ë°©ì‹] ---
    print(f"ğŸ” PwC ê¸°ìˆ  ì„¹ì…˜ ìˆ˜ìƒ‰ ì¤‘ (ë²”ìœ„ í™•ëŒ€)...")
    pwc_url = "https://www.pwc.com/gx/en/issues/technology.html"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    
    try:
        res = requests.get(pwc_url, headers=headers, timeout=30)
        if res.status_code == 200:
            soup = BeautifulSoup(res.text, 'html.parser')
            pwc_count = 0
            # a, h3, h4, span íƒœê·¸ë¥¼ ëª¨ë‘ ë’¤ì ¸ì„œ ë°ì´í„°ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            potential_items = soup.find_all(['a', 'h3', 'h4', 'span'])
            
            for item in potential_items:
                text = item.get_text().strip()
                # í•„í„°: ì œëª© ê¸¸ì´(25~150ì) ë° í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
                if 25 < len(text) < 150:
                    upper_text = text.upper()
                    if any(kw in upper_text for kw in ['AI', 'GEN', 'DIGITAL', 'INTELLIGENCE', 'TECH', 'CLOUD', 'DATA']):
                        
                        # ë§í¬ ì¶”ì¶œ ë¡œì§
                        link = ""
                        if item.name == 'a': 
                            link = item.get('href', '')
                        else:
                            parent_a = item.find_parent('a')
                            if parent_a: link = parent_a.get('href', '')
                        
                        if link and not link.startswith('#'):
                            full_url = f"https://www.pwc.com{link}" if link.startswith('/') else link
                            
                            # ì¤‘ë³µ ì œê±°
                            if not any(d['ì›ë¬¸'] == text for d in new_data):
                                try:
                                    title_ko = translator.translate(text, dest='ko').text
                                    new_data.append({
                                        "ê¸°ê´€": "PwC", 
                                        "ë°œí–‰ì¼": collected_date,
                                        "ì œëª©": title_ko, 
                                        "ì›ë¬¸": text, 
                                        "ë§í¬": full_url, 
                                        "ìˆ˜ì§‘ì¼": collected_date
                                    })
                                    pwc_count += 1
                                    print(f"   âœ¨ PwC ë°œê²¬: {title_ko[:20]}...")
                                except:
                                    continue
                    if pwc_count >= 10: break
            print(f"   âœ… PwCì—ì„œ {pwc_count}ê±´ ì •ë°€ í™•ë³´!")
        else:
            print(f"   âŒ PwC ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {res.status_code})")
    except Exception as e:
        print(f"   âŒ PwC ì—ëŸ¬: {e}")

    # --- [ì €ì¥] ---
    if new_data:
        # ìµœì‹ ìˆœ ì •ë ¬
        new_data.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬", "ìˆ˜ì§‘ì¼"])
            writer.writeheader()
            writer.writerows(new_data)
        print(f"\nğŸ‰ ì„±ê³µ! ì´ {len(new_data)}ê±´ì˜ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nğŸ’¡ ìˆ˜ì§‘ëœ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
