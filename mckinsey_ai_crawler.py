import requests
from bs4 import BeautifulSoup
import csv
import os
import time  # ì¬ì‹œë„ë¥¼ ìœ„í•œ ì‹œê°„ ì§€ì—°ìš©
from datetime import datetime
from googletrans import Translator

def main():
    target_url = "https://www.mckinsey.com/capabilities/quantumblack/our-insights"
    file_name = 'mckinsey_ai_report.csv'
    translator = Translator()
    
    print(f"ğŸ“¡ [McKinsey] AI ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ì‹œì‘ (ì¸ë‚´ì‹¬ ëª¨ë“œ ê°€ë™)...")

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
    }

    # ğŸ’¡ ìµœëŒ€ 3ë²ˆê¹Œì§€ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.
    for attempt in range(3):
        try:
            # ğŸ’¡ timeoutì„ 60ì´ˆë¡œ ë„‰ë„‰í•˜ê²Œ ëŠ˜ë ¸ìŠµë‹ˆë‹¤.
            response = requests.get(target_url, headers=headers, timeout=60)
            response.raise_for_status() # ì—°ê²° ì˜¤ë¥˜ í™•ì¸
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = soup.find_all(['h3', 'h4'], limit=20)
            
            new_data = []
            for item in articles:
                title_en = item.get_text().strip()
                link_tag = item.find_parent('a') or item.find('a') or item.find_previous('a')
                
                if len(title_en) > 20 and link_tag:
                    href = link_tag.get('href', '')
                    full_url = f"https://www.mckinsey.com{href}" if href.startswith('/') else href
                    
                    try:
                        translated = translator.translate(title_en, src='en', dest='ko')
                        title_ko = translated.text
                    except:
                        title_ko = title_en

                    print(f"   âœ… ìˆ˜ì§‘ ì™„ë£Œ: {title_ko[:30]}...")
                    new_data.append({
                        "ê¸°ê´€": "McKinsey",
                        "ë°œí–‰ì¼": datetime.now().strftime("%Y-%m-%d"),
                        "ì œëª©": title_ko,
                        "ì›ë¬¸": title_en,
                        "ë§í¬": full_url
                    })
                    if len(new_data) >= 10: break

            if new_data:
                with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
                    writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬"])
                    writer.writeheader()
                    writer.writerows(new_data)
                print(f"ğŸ‰ ë“œë””ì–´ ì„±ê³µ! {len(new_data)}ê±´ ì €ì¥ ì™„ë£Œ.")
                return # ì„±ê³µí–ˆìœ¼ë‹ˆ í•¨ìˆ˜ ì¢…ë£Œ

        except Exception as e:
            print(f"âš ï¸ {attempt+1}ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨: {e}")
            if attempt < 2:
                print("   5ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤...")
                time.sleep(5)
            else:
                print("âŒ ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
