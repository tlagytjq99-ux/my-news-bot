import requests
from bs4 import BeautifulSoup
import feedparser
import csv
import os
import time
from datetime import datetime
from googletrans import Translator

def main():
    file_name = 'ai_market_intelligence.csv'
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")
    
    print(f"ğŸ“¡ [í†µí•© ì—”ì§„] ì „ëµ ë¦¬í¬íŠ¸ ì •ë°€ ìˆ˜ì§‘ ì‹œì‘...")
    new_data = []

    # --- [McKinsey ìˆ˜ì§‘] ---
    try:
        mck_feed = feedparser.parse("https://www.mckinsey.com/insights/rss")
        for entry in mck_feed.entries[:12]:
            try:
                title_ko = translator.translate(entry.title, dest='ko').text
                new_data.append({
                    "ê¸°ê´€": "McKinsey",
                    "ë°œí–‰ì¼": time.strftime('%Y-%m-%d', entry.published_parsed) if 'published_parsed' in entry else collected_date,
                    "ì œëª©": title_ko, "ì›ë¬¸": entry.title, "ë§í¬": entry.link, "ìˆ˜ì§‘ì¼": collected_date
                })
            except: continue
        print(f"   âœ… McKinsey ìˆ˜ì§‘ ì™„ë£Œ")
    except: print(f"   âš ï¸ McKinsey ì˜¤ë¥˜")

    # --- [PwC ì •ë°€ íƒ€ê²© ìˆ˜ì§‘] ---
    print(f"ğŸ” PwC ë¦¬í¬íŠ¸ ë³¸ì§„(Technology) ê³µëµ ì¤‘...")
    pwc_url = "https://www.pwc.com/gx/en/issues/technology.html"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"}
    
    try:
        res = requests.get(pwc_url, headers=headers, timeout=30)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # ğŸ’¡ PwCì˜ 'ì§„ì§œ ë¦¬í¬íŠ¸'ê°€ ë‹´ê¸´ ì¹´ë“œ ì˜ì—­ë§Œ ì¡°ì¤€í•©ë‹ˆë‹¤.
        # h3 íƒœê·¸ ì¤‘ í´ë˜ìŠ¤ëª…ì´ titleì„ í¬í•¨í•˜ê±°ë‚˜, íŠ¹ì • íŒ¨í„´ì„ ê°€ì§„ ê²ƒë“¤ ìœ„ì£¼
        articles = soup.select('div.pwc-feature-tile__content, div.item-content') 
        
        pwc_count = 0
        for art in articles:
            # 1. ì œëª© ì¶”ì¶œ (h3 ë˜ëŠ” h4 íƒœê·¸)
            title_tag = art.find(['h3', 'h4', 'span'], class_=lambda x: x and 'title' in x.lower())
            if not title_tag:
                title_tag = art.find(['h3', 'h4'])
            
            if title_tag:
                title_en = title_tag.get_text().strip()
                
                # ë©”ë‰´ ì´ë¦„(ë„ˆë¬´ ì§§ì€ ê²ƒ)ì€ ë²„ë¦¬ê³ , ë¦¬í¬íŠ¸ë‹¤ìš´ ì œëª©ë§Œ í•„í„°ë§
                if len(title_en) > 30: 
                    # 2. ë§í¬ ì¶”ì¶œ
                    link_tag = art.find('a', href=True)
                    if link_tag:
                        link = link_tag['href']
                        full_url = f"https://www.pwc.com{link}" if link.startswith('/') else link
                        
                        # ì¤‘ë³µ ì œê±°
                        if not any(d['ì›ë¬¸'] == title_en for d in new_data):
                            try:
                                title_ko = translator.translate(title_en, dest='ko').text
                                new_data.append({
                                    "ê¸°ê´€": "PwC", "ë°œí–‰ì¼": collected_date,
                                    "ì œëª©": title_ko, "ì›ë¬¸": title_en, "ë§í¬": full_url, "ìˆ˜ì§‘ì¼": collected_date
                                })
                                pwc_count += 1
                            except: continue
            if pwc_count >= 10: break
            
        print(f"   âœ… PwC ì •ë°€ ë¦¬í¬íŠ¸ {pwc_count}ê±´ í™•ë³´!")
    except Exception as e:
        print(f"   âŒ PwC ì—ëŸ¬: {e}")

    # --- [ì €ì¥] ---
    if new_data:
        new_data.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬", "ìˆ˜ì§‘ì¼"])
            writer.writeheader()
            writer.writerows(new_data)
        print(f"\nğŸ‰ ì„±ê³µ! ì´ì œ ì°Œêº¼ê¸° ì—†ëŠ” ì§„ì§œ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
