import requests
import csv
import time

def main():
    results = []
    page = 1
    
    # ìˆ˜ì§‘í•  ë¬¸ì„œ ìœ í˜• ì •ì˜
    # PRESDOCU: ëŒ€í†µë ¹ ë¬¸ì„œ, RULE: ìµœì¢… ê·œì¹™, PRORULE: ê·œì¹™ ì œì • ì˜ˆê³ , NOTICE: ì¼ë°˜ ê³µê³ 
    doc_types = ["PRESDOCU", "RULE", "PRORULE", "NOTICE"]
    
    print(f"ğŸš€ 2025ë…„ ì „ìˆ˜ ì¡°ì‚¬ ì‹œì‘ (ëŒ€ìƒ: {', '.join(doc_types)})")
    print("âš¡ ë²ˆì—­ ë‹¨ê³„ë¥¼ ì œì™¸í•˜ì—¬ ìˆ˜ì§‘ ì†ë„ê°€ ëŒ€í­ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")

    while True:
        api_url = "https://www.federalregister.gov/api/v1/documents.json"
        params = {
            "conditions[publication_date][year]": "2025",
            "conditions[type][]": doc_types,
            "order": "newest",
            "per_page": 100,
            "page": page,
            "fields[]": ["title", "publication_date", "type", "agency_names", "html_url", "document_number"]
        }

        try:
            response = requests.get(api_url, params=params, timeout=30)
            if response.status_code != 200:
                print(f"âš ï¸ {page}í˜ì´ì§€ í˜¸ì¶œ ì‹¤íŒ¨ (ì½”ë“œ: {response.status_code})")
                break
            
            data = response.json()
            docs = data.get('results', [])
            if not docs:
                break

            print(f"ğŸ“¥ {page}í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘... (í˜„ì¬ ëˆ„ì : {len(results) + len(docs)}ê±´)")

            for doc in docs:
                agencies = doc.get('agency_names', [])
                agency_text = ", ".join(agencies) if agencies else "White House / Presidential"

                # ë¬¸ì„œ ìœ í˜• í•œê¸€ ë§¤í•‘ (ë°ì´í„° ì •ë¦¬ìš©)
                type_map = {
                    "Rule": "ìµœì¢… ê·œì¹™(Rule)",
                    "Proposed Rule": "ê·œì¹™ ì œì • ì˜ˆê³ (Proposed Rule)",
                    "Notice": "ê³µê³ (Notice)",
                    "Presidential Document": "ëŒ€í†µë ¹ ë¬¸ì„œ"
                }
                doc_type_en = doc.get('type', '')
                doc_type_ko = type_map.get(doc_type_en, doc_type_en)

                results.append({
                    "ë°œí–‰ì¼": doc.get('publication_date'),
                    "ë°œí–‰ë¶€ì²˜": agency_text,
                    "ë¬¸ì„œì¢…ë¥˜": doc_type_ko,
                    "ì œëª©(ì˜ë¬¸)": doc.get('title'),
                    "ì›ë¬¸ë§í¬": doc.get('html_url'),
                    "ë¬¸ì„œë²ˆí˜¸": doc.get('document_number')
                })
            
            page += 1
            # ë²ˆì—­ì„ ì•ˆ í•˜ë¯€ë¡œ ëŒ€ê¸° ì‹œê°„ì„ ì¤„ì—¬ë„ ì•ˆì „í•©ë‹ˆë‹¤ (0.2ì´ˆ)
            time.sleep(0.2) 

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

    # CSV ì €ì¥
    if results:
        file_name = 'Federal_Register_2025_Full_Scraping.csv'
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ë°œí–‰ì¼", "ë°œí–‰ë¶€ì²˜", "ë¬¸ì„œì¢…ë¥˜", "ì œëª©(ì˜ë¬¸)", "ì›ë¬¸ë§í¬", "ë¬¸ì„œë²ˆí˜¸"])
            writer.writeheader()
            writer.writerows(results)
        print(f"\nğŸ ì „ìˆ˜ ì¡°ì‚¬ ì™„ë£Œ! ì´ {len(results)}ê±´ì˜ ë°ì´í„°ë¥¼ '{file_name}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
