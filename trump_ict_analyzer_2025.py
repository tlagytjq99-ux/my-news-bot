import requests
import csv
import time

def fetch_us_data():
    results = []
    # ì¤‘ë³µ ìˆ˜ì§‘ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì¥ì¹˜
    seen_documents = set()
    
    # ê´€ì‹¬ ìˆëŠ” ë¬¸ì„œ ìœ í˜•: ëŒ€í†µë ¹ ë¬¸ì„œ, ê·œì¹™, ê·œì¹™ì˜ˆê³ , ê³µê³ 
    doc_types = ["PRESDOCU", "RULE", "PRORULE", "NOTICE"]
    
    print("ğŸ‡ºğŸ‡¸ [ë¯¸êµ­ ê´€ë³´ 2025] ë°ì´í„° ì „ìˆ˜ ì¡°ì‚¬ ì¬ì‹œì‘...")

    # 1ì›”ë¶€í„° 12ì›”ê¹Œì§€ ìˆœì°¨ì ìœ¼ë¡œ ì ‘ê·¼ (API ë¶€í•˜ ë¶„ì‚°)
    for month in range(1, 13):
        start_date = f"2025-{month:02d}-01"
        if month == 12:
            end_date = "2025-12-31"
        else:
            end_date = f"2025-{month+1:02d}-01"
            
        print(f"\nğŸ“… ë¶„ì„ êµ¬ê°„: {start_date} ~ {end_date}")
        
        page = 1
        while True:
            api_url = "https://www.federalregister.gov/api/v1/documents.json"
            params = {
                "conditions[publication_date][gte]": start_date,
                "conditions[publication_date][lt]": end_date,
                "conditions[type][]": doc_types,
                "per_page": 100,  # í•œ ë²ˆì— 100ê°œì”© ì•ˆì „í•˜ê²Œ
                "page": page,
                "fields[]": ["title", "publication_date", "type", "agency_names", "html_url", "document_number"]
            }

            try:
                # 15ì´ˆ ì•ˆì— ì‘ë‹µ ì—†ìœ¼ë©´ ë‹¤ì‹œ ì‹œë„í•˜ë„ë¡ ì„¤ì •
                response = requests.get(api_url, params=params, timeout=15)
                
                if response.status_code != 200:
                    print(f"âš ï¸ {page}í˜ì´ì§€ ì‘ë‹µ ì˜¤ë¥˜ (ì½”ë“œ: {response.status_code})")
                    break
                
                data = response.json()
                docs = data.get('results', [])
                
                if not docs: # í•´ë‹¹ ì›”ì˜ ë°ì´í„°ê°€ ëë‚¬ìœ¼ë©´ ë‹¤ìŒ ë‹¬ë¡œ
                    break

                # ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ ì¶œë ¥ (ëŒ€í‘œë‹˜ì´ ë¡œê·¸ì—ì„œ ë³´ì‹¤ ë‚´ìš©)
                print(f"ğŸ“¥ {month}ì›” ìˆ˜ì§‘ ì¤‘... ({page}í˜ì´ì§€ / ëˆ„ì : {len(results)}ê±´)", end="\r", flush=True)

                for doc in docs:
                    doc_id = doc.get('document_number')
                    if doc_id not in seen_documents:
                        seen_documents.add(doc_id)
                        agencies = doc.get('agency_names', [])
                        results.append({
                            "ë°œí–‰ì¼": doc.get('publication_date'),
                            "ë¶€ì²˜": ", ".join(agencies) if agencies else "White House",
                            "ì¢…ë¥˜": doc.get('type'),
                            "ì œëª©": doc.get('title'),
                            "ì›ë¬¸ë§í¬": doc.get('html_url')
                        })
                
                page += 1
                time.sleep(0.2) # ë¯¸êµ­ ì„œë²„ê°€ í™”ë‚´ì§€ ì•Šê²Œ ì ê¹ì”© ì‰¬ì–´ì¤Œ
                
            except Exception as e:
                print(f"\nâŒ í†µì‹  ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                time.sleep(5) # ì—ëŸ¬ ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ë‹¤ìŒ ë‹¨ê³„ ì‹œë„
                break
                
    # íŒŒì¼ ì €ì¥
    if results:
        file_name = 'Federal_Register_2025_Master.csv'
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ë°œí–‰ì¼", "ë¶€ì²˜", "ì¢…ë¥˜", "ì œëª©", "ì›ë¬¸ë§í¬"])
            writer.writeheader()
            writer.writerows(results)
        print(f"\n\nâœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(results)}ê±´ì˜ ë°ì´í„°ë¥¼ '{file_name}'ì— ë‹´ì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    fetch_us_data()
