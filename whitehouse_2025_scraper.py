import feedparser
import csv
import urllib.parse
from datetime import datetime
from googlenewsdecoder import gnewsdecoder
import time

def main():
    # 1. 2025ë…„ ë°ì´í„°ë§Œ ì •ë°€ íƒ€ê²ŸíŒ…í•˜ëŠ” ì¿¼ë¦¬
    target_site = "whitehouse.gov/presidential-actions/"
    # 2025-01-01 ì´í›„ ë°ì´í„°ë§Œ ê°€ì ¸ì˜¤ë„ë¡ êµ¬ê¸€ì— ëª…ë ¹
    query = f"site:{target_site} after:2025-01-01"
    encoded_query = urllib.parse.quote(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"

    # 2. ì‚¬ì§„ ì† 46ê°œ ì¹´í…Œê³ ë¦¬ (í•µì‹¬ í‚¤ì›Œë“œ ë§¤í•‘)
    category_db = {
        "1. 5G/6G Network": ["5G", "6G", "Open RAN", "Terahertz", "Network slicing"]
    }

    print(f"ğŸ“… 2025ë…„ ë°±ì•…ê´€ ì •ì±… ë°ì´í„° ì •ë°€ ìˆ˜ì§‘ ì‹œì‘...")

    try:
        feed = feedparser.parse(rss_url)
        results = []

        for entry in feed.entries:
            try:
                # ë°œí–‰ì¼ íŒŒì‹± ë° 2025ë…„ ê²€ì¦
                pub_date = datetime(*entry.published_parsed[:3])
                if pub_date.year < 2025:
                    continue # 2025ë…„ ì´ì „ ë°ì´í„°ëŠ” ê³¼ê°íˆ ì‚­ì œ

                title = entry.title.split(' - ')[0].strip()
                
                # ì•„ì¹´ì´ë¸Œ/ëª©ì°¨ í˜ì´ì§€ ì œê±° (ì§„ì§œ ë¬¸ì„œë§Œ ìˆ˜ì§‘)
                if any(noise in title for noise in ["Archives", "Page", "Presidential Actions"]):
                    continue

                # êµ¬ê¸€ ë§í¬ ìš°íšŒ ë””ì½”ë”©
                try:
                    decoded = gnewsdecoder(entry.link)
                    actual_url = decoded.get('decoded_url', entry.link)
                except:
                    actual_url = entry.link

                # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ (46ê°œ í•„í„°ë§)
                matched_cats = []
                for cat, kws in category_db.items():
                    if any(kw.lower() in title.lower() for kw in kws):
                        matched_cats.append(cat)

                results.append({
                    "ë°œí–‰ì¼": pub_date.strftime('%Y-%m-%d'),
                    "ì¹´í…Œê³ ë¦¬": ", ".join(matched_cats) if matched_cats else "ì¼ë°˜ ì •ì±…",
                    "ë¬¸ì„œìœ í˜•": "Executive Order" if "/executive-orders/" in actual_url else "Presidential Action",
                    "ì œëª©": title,
                    "ì›ë¬¸ë§í¬": actual_url
                })
                time.sleep(0.05)
            except: continue

        # 3. CSV ì €ì¥
        file_name = 'whitehouse_2025_report.csv'
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ë°œí–‰ì¼", "ì¹´í…Œê³ ë¦¬", "ë¬¸ì„œìœ í˜•", "ì œëª©", "ì›ë¬¸ë§í¬"])
            writer.writeheader()
            
            if results:
                # ìµœì‹  ë‚ ì§œìˆœ ì •ë ¬
                results.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)
                writer.writerows(results)
                print(f"âœ… ì„±ê³µ: ì´ {len(results)}ê±´ì˜ 2025ë…„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
            else:
                print("âš ï¸ 2025ë…„ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
