import feedparser
import csv
import urllib.parse
from datetime import datetime
from googletrans import Translator
from googlenewsdecoder import gnewsdecoder

def main():
    # ğŸ¯ ë°±ì•…ê´€ ì •ë°€ íƒ€ê²ŸíŒ… ì¿¼ë¦¬
    # í–‰ì •ëª…ë ¹(Executive Order), íŒ©íŠ¸ì‹œíŠ¸(Fact Sheet), ì „ëµ(Strategy) ë“± í•µì‹¬ ë¬¸ì„œ ìœ„ì£¼
    query = 'site:whitehouse.gov (intitle:"Artificial Intelligence" OR intitle:AI OR "Executive Order on AI") -intitle:briefing -intitle:press'
    encoded_query = urllib.parse.quote(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    
    file_name = 'whitehouse_ai_policy.csv'
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ‡ºğŸ‡¸ ë°±ì•…ê´€ AI í•µì‹¬ ì •ì±… ìˆ˜ì§‘ ì‹œì‘...")
    final_data = []

    try:
        feed = feedparser.parse(rss_url)
        # ìµœì‹ ìˆœ ì •ë ¬ í›„ ìƒìœ„ 10ê°œ ë¶„ì„ (ë°±ì•…ê´€ì€ ì¤‘ìš”ë„ê°€ ë†’ìœ¼ë‹ˆ 10ê°œê¹Œì§€ ë´…ë‹ˆë‹¤)
        entries = sorted(feed.entries, key=lambda x: x.get('published_parsed'), reverse=True)[:10]
        
        for entry in entries:
            title_en = entry.title.split(' - ')[0]
            
            # 1. ë„ˆë¬´ ì§§ì€ ì œëª©(ë‹¨ìˆœ ì¹´í…Œê³ ë¦¬ ë“±) ì œì™¸
            if len(title_en.split()) <= 3:
                continue

            print(f"ğŸ”‘ ë§í¬ í•´ë… ë° ë¶„ì„ ì¤‘: {title_en[:40]}...")
            
            # 2. ì•”í˜¸ í•´ë…ê¸°ë¡œ ì›ë³¸ ë§í¬ ì¶”ì¶œ (ì„±ê³µì˜ í•µì‹¬)
            try:
                decoded = gnewsdecoder(entry.link)
                actual_link = decoded.get('decoded_url', entry.link)
            except:
                actual_link = entry.link

            # 3. ë‚ ì§œ ì²˜ë¦¬
            pub_date = datetime(*entry.published_parsed[:6]).strftime('%Y-%m-%d') if hasattr(entry, 'published_parsed') else collected_date

            # 4. í•œêµ­ì–´ ë²ˆì—­
            try:
                title_ko = translator.translate(title_en.strip(), dest='ko').text
            except:
                title_ko = title_en

            final_data.append({
                "ê¸°ê´€": "WhiteHouse",
                "ë°œí–‰ì¼": pub_date,
                "ì œëª©": title_ko,
                "ì›ë¬¸": title_en,
                "ë§í¬": actual_link,
                "ìˆ˜ì§‘ì¼": collected_date
            })

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ğŸ’¾ ê²°ê³¼ ì €ì¥ (ì¸ì½”ë”©: utf-8-sigë¡œ ì—‘ì…€ í•œê¸€ ê¹¨ì§ ë°©ì§€)
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "ë§í¬", "ìˆ˜ì§‘ì¼"])
        writer.writeheader()
        if final_data:
            writer.writerows(final_data)
            print(f"âœ… ì™„ë£Œ! ë°±ì•…ê´€ í•µì‹¬ ì •ì±… {len(final_data)}ê±´ ì €ì¥ ì™„ë£Œ.")
        else:
            print("âš ï¸ ì¡°ê±´ì— ë§ëŠ” ìµœì‹  ì •ì±… ë¬¸ì„œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
