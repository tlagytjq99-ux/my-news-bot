import feedparser
import csv
import urllib.parse
from datetime import datetime
from googletrans import Translator
from googlenewsdecoder import gnewsdecoder

def main():
    # ğŸ¯ ì¿¼ë¦¬ ìˆ˜ì •: ë²”ìœ„ë¥¼ ë„“í˜€ì„œ ì¼ë°˜ ì›¹í˜ì´ì§€ë„ ìˆ˜ì§‘ë˜ë„ë¡ í•©ë‹ˆë‹¤.
    # (ë‹¨, ìµœì†Œí•œì˜ AI ê´€ë ¨ì„±ì€ ìœ ì§€)
    query = 'site:whitehouse.gov (intitle:"Artificial Intelligence" OR intitle:AI)'
    encoded_query = urllib.parse.quote(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    
    file_name = 'whitehouse_ai_policy.csv'
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ‡ºğŸ‡¸ ë°±ì•…ê´€ AI ì¢…í•© ìˆ˜ì§‘ ì‹œì‘ (PDF ìë™ íŒë³„)...")
    final_data = []

    try:
        feed = feedparser.parse(rss_url)
        # 20ê°œ ì •ë„ ë„‰ë„‰íˆ ë¶„ì„í•˜ì—¬ ì›¹ê³¼ PDFê°€ ì„ì´ê²Œ í•©ë‹ˆë‹¤.
        entries = sorted(feed.entries, key=lambda x: x.get('published_parsed'), reverse=True)[:20]
        
        for entry in entries:
            title_en = entry.title.split(' - ')[0]
            if len(title_en.split()) <= 2: continue

            # 1. ë§í¬ í•´ë…
            try:
                decoded = gnewsdecoder(entry.link)
                actual_link = decoded.get('decoded_url', entry.link)
            except:
                actual_link = entry.link

            # ğŸ’¡ 2. PDF ì—¬ë¶€ íŒë³„ (í•µì‹¬ ë¡œì§)
            is_pdf = "YES" if actual_link.lower().endswith('.pdf') or ".pdf?" in actual_link.lower() else "NO"

            # 3. ë‚ ì§œ ë° ë²ˆì—­
            pub_date = datetime(*entry.published_parsed[:6]).strftime('%Y-%m-%d') if hasattr(entry, 'published_parsed') else collected_date
            try:
                title_ko = translator.translate(title_en.strip(), dest='ko').text
            except:
                title_ko = title_en

            # ğŸ’¡ 4. ì œëª© ì˜†ì— í‘œì‹œ (ì›í•˜ì‹ ë‹¤ë©´ ì œëª©ì— [PDF]ë¥¼ ë¶™ì¼ ìˆ˜ë„ ìˆê³ , ì»¬ëŸ¼ìœ¼ë¡œë§Œ ëº„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤)
            display_title = f"[PDF] {title_ko}" if is_pdf == "YES" else title_ko

            final_data.append({
                "ê¸°ê´€": "WhiteHouse",
                "ë°œí–‰ì¼": pub_date,
                "ì œëª©": display_title,
                "ì›ë¬¸": title_en,
                "PDFì—¬ë¶€": is_pdf, # âœ… ìƒˆ ì»¬ëŸ¼
                "ë§í¬": actual_link,
                "ìˆ˜ì§‘ì¼": collected_date
            })

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ğŸ’¾ ê²°ê³¼ ì €ì¥ (ì»¬ëŸ¼ ìˆœì„œì— 'PDFì—¬ë¶€' ì¶”ê°€)
    fieldnames = ["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "PDFì—¬ë¶€", "ë§í¬", "ìˆ˜ì§‘ì¼"]
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(final_data)
        print(f"âœ… ì™„ë£Œ! ì´ {len(final_data)}ê±´ ì €ì¥ (PDF íŒë³„ ì™„ë£Œ).")

if __name__ == "__main__":
    main()
