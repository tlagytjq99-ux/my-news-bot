import feedparser
import csv
import urllib.parse
from datetime import datetime
from googletrans import Translator
from googlenewsdecoder import gnewsdecoder

def main():
    # ğŸ¯ ì¿¼ë¦¬ ê³ ë„í™”: 
    # 1. AIì™€ í•¨ê»˜ 'Strategy', 'Report', 'Framework', 'Policy' ê°™ì€ ë‹¨ì–´ë¥¼ ê²°í•©
    # 2. ë…¸ì´ì¦ˆ(Cuba, Wildfire, School Choice ë“±)ë¥¼ ì¼ìœ¼í‚¤ëŠ” ì •ì¹˜ í‚¤ì›Œë“œ ê°•ì œ ì œì™¸ (-)
    query = 'site:whitehouse.gov (AI OR "Artificial Intelligence") (Report OR Strategy OR Framework OR Policy OR "Executive Order") -Cuba -Wildfire -School -Recovery'
    
    encoded_query = urllib.parse.quote(query)
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
    
    file_name = 'whitehouse_ai_policy.csv'
    translator = Translator()
    collected_date = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ‡ºğŸ‡¸ ë°±ì•…ê´€ AI ì •ì±… ë¦¬í¬íŠ¸ ì •ë°€ ìˆ˜ì§‘ ì‹œì‘...")
    final_data = []

    try:
        feed = feedparser.parse(rss_url)
        # ì¤‘ìš”ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ 15ê°œë¥¼ ë¨¼ì € ì‚´í•ë‹ˆë‹¤.
        entries = feed.entries[:15]
        
        for entry in entries:
            title_en = entry.title.split(' - ')[0]
            
            # ğŸ’¡ [í•„í„° ì¶”ê°€] ì œëª©ì— AI ê´€ë ¨ í•µì‹¬ì–´ê°€ ì—†ìœ¼ë©´ ê³¼ê°íˆ íŒ¨ìŠ¤
            ai_keywords = ['AI', 'ARTIFICIAL', 'INTELLIGENCE', 'ALGORITHM', 'TECHNOLOGY']
            if not any(kw in title_en.upper() for kw in ai_keywords):
                continue

            # ë§í¬ í•´ë…
            try:
                decoded = gnewsdecoder(entry.link)
                actual_link = decoded.get('decoded_url', entry.link)
            except:
                actual_link = entry.link

            # ğŸ’¡ [PDF íŒë³„]
            is_pdf = "YES" if actual_link.lower().endswith('.pdf') or ".pdf?" in actual_link.lower() else "NO"
            display_prefix = "[PDF] " if is_pdf == "YES" else ""

            pub_date = datetime(*entry.published_parsed[:6]).strftime('%Y-%m-%d') if hasattr(entry, 'published_parsed') else collected_date

            try:
                title_ko = translator.translate(title_en.strip(), dest='ko').text
            except:
                title_ko = title_en

            final_data.append({
                "ê¸°ê´€": "WhiteHouse",
                "ë°œí–‰ì¼": pub_date,
                "ì œëª©": f"{display_prefix}{title_ko}",
                "ì›ë¬¸": title_en,
                "PDFì—¬ë¶€": is_pdf,
                "ë§í¬": actual_link,
                "ìˆ˜ì§‘ì¼": collected_date
            })

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ìµœì‹ ìˆœ ì •ë ¬ í›„ ì €ì¥
    final_data.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)

    fieldnames = ["ê¸°ê´€", "ë°œí–‰ì¼", "ì œëª©", "ì›ë¬¸", "PDFì—¬ë¶€", "ë§í¬", "ìˆ˜ì§‘ì¼"]
    with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(final_data)
        print(f"âœ… ì •ë°€ ìˆ˜ì§‘ ì™„ë£Œ! {len(final_data)}ê±´ì˜ AI ê´€ë ¨ ì •ì±… í™•ë³´.")

if __name__ == "__main__":
    main()
