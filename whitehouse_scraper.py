import requests
from bs4 import BeautifulSoup
import csv
from datetime import datetime, timedelta
import os

def main():
    # 1. ëŒ€ìƒ URL ë° 7ì¼ ì „ ë‚ ì§œ ì„¤ì •
    url = "https://www.whitehouse.gov/briefing-room/"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    }
    
    # í•œêµ­ ì‹œê°„ ê¸°ì¤€ì´ ì•„ë‹Œ í˜„ì§€ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ë„‰ë„‰í•˜ê²Œ 7ì¼+@ ì„¤ì •
    one_week_ago = datetime.now() - timedelta(days=8)
    
    print(f"ğŸ“¡ ë°±ì•…ê´€ ë‰´ìŠ¤ë£¸ ì§ì ‘ í¬ë¡¤ë§ ì‹œì‘: {url}")

    try:
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            print(f"âŒ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return

        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ë°±ì•…ê´€ ë‰´ìŠ¤ ì•„ì´í…œì€ ë³´í†µ 'news-item' í´ë˜ìŠ¤ë‚˜ 'article' íƒœê·¸ ë‚´ì— ì¡´ì¬
        # ìµœì‹  êµ¬ì¡°ì— ë§ì¶° ë°˜ë³µë¬¸ ì‹¤í–‰
        news_items = soup.select('article')
        all_data = []

        for item in news_items:
            try:
                # ì œëª© ë° ë§í¬ ì¶”ì¶œ
                title_tag = item.select_one('h2 a') or item.select_one('a')
                title = title_tag.get_text(strip=True)
                link = title_tag['href']

                # ë‚ ì§œ ì¶”ì¶œ (ë³´í†µ <time> íƒœê·¸ ì‚¬ìš©)
                date_tag = item.select_one('time')
                if date_tag:
                    date_str = date_tag.get_text(strip=True) # ì˜ˆ: January 31, 2026
                    # ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜
                    pub_date = datetime.strptime(date_str, "%B %d, %Y")
                    
                    # 7ì¼ ì´ë‚´ ë°ì´í„°ë§Œ í•„í„°ë§
                    if pub_date >= one_week_ago:
                        all_data.append({
                            "ë°œí–‰ì¼": pub_date.strftime('%Y-%m-%d'),
                            "ì œëª©": title,
                            "ë§í¬": link
                        })
            except Exception as e:
                continue

        # 2. CSV ì €ì¥
        file_name = 'whitehouse_news_decoded.csv'
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ë°œí–‰ì¼", "ì œëª©", "ë§í¬"])
            writer.writeheader()
            if all_data:
                writer.writerows(all_data)
                print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_data)}ê±´ì˜ ìµœì‹  ë³´ë„ìë£Œë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤.")
            else:
                print("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ìµœê·¼ 7ì¼ ë‚´ ê²Œì‹œë¬¼ì´ ì—†ê±°ë‚˜ êµ¬ì¡° ë³€ê²½)")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
