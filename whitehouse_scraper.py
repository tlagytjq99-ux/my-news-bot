import feedparser
import csv
import urllib.parse
from datetime import datetime, timedelta
import time

def main():
    # 1. ê¸°ê°„ ì„¤ì • (ìµœê·¼ 14ì¼ë¡œ ë” ë„‰ë„‰í•˜ê²Œ - íšŒì˜ìš© ë°ì´í„° í™•ë³´)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=14)
    
    # 2. êµ¬ê¸€ì´ ê°€ì¥ ì„ í˜¸í•˜ëŠ” ê²€ìƒ‰ ì—°ì‚°ìë¡œ ë³€ê²½
    # site ì „ì²´ì—ì„œ ê²€ìƒ‰í•˜ë˜, ì œëª©ì´ë‚˜ ë³¸ë¬¸ì— Briefing Roomì´ í¬í•¨ëœ ê²ƒ ìœ„ì£¼
    query = 'site:whitehouse.gov "Briefing Room"'
    encoded_query = urllib.parse.quote(query)
    
    # hl=en-US, gl=USë¥¼ ëª…ì‹œí•˜ì—¬ ë¯¸êµ­ ë³¸í†  ë°ì´í„° ê°•ì œ í˜¸ì¶œ
    rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"

    print(f"ğŸ“¡ [ê¸´ê¸‰] êµ¬ê¸€ ì¸ë±ìŠ¤ ê°•ì œ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")

    try:
        feed = feedparser.parse(rss_url)
        all_data = []

        if not feed.entries:
            # ë§Œì•½ ì´ê²ƒë„ ì•ˆ ë‚˜ì˜¤ë©´ ì¼ë°˜ì ì¸ 'White House' í‚¤ì›Œë“œë¡œ 3ì°¨ ì‹œë„
            print("âš ï¸ 2ì°¨ ì¿¼ë¦¬ ì‹¤íŒ¨, 3ì°¨ ê´‘ë²”ìœ„ ê²€ìƒ‰ ì‹œë„...")
            query = 'White House "Statements and Releases"'
            encoded_query = urllib.parse.quote(query)
            rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
            feed = feedparser.parse(rss_url)

        for entry in feed.entries:
            # ë‚ ì§œ ì²˜ë¦¬
            try:
                pub_date_struct = entry.published_parsed
                pub_date_obj = datetime(*pub_date_struct[:3])
            except:
                continue

            # ë‚ ì§œ í•„í„°ë§
            if pub_date_obj >= start_date:
                all_data.append({
                    "ë°œí–‰ì¼": pub_date_obj.strftime('%Y-%m-%d'),
                    "ì œëª©": entry.title.split(' - ')[0].strip(),
                    "ë§í¬": entry.link
                })

        # 3. CSV ì €ì¥
        file_name = 'whitehouse_news_decoded.csv'
        with open(file_name, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=["ë°œí–‰ì¼", "ì œëª©", "ë§í¬"])
            writer.writeheader()
            if all_data:
                # ìµœì‹ ìˆœ ì •ë ¬
                all_data.sort(key=lambda x: x['ë°œí–‰ì¼'], reverse=True)
                writer.writerows(all_data)
                print(f"âœ… [ì„±ê³µ] {len(all_data)}ê±´ì˜ ë°ì´í„°ë¥¼ í™•ë³´í–ˆìŠµë‹ˆë‹¤!")
            else:
                print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ëŠ” ìˆìœ¼ë‚˜ ìµœê·¼ 14ì¼ ì´ë‚´ì˜ ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()
